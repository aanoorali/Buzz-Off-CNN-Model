{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae6385",
   "metadata": {},
   "source": [
    "Varroa Mite Detection V1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9629b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 1: Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f75b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 2: Load Data and Preprocess\n",
    "\n",
    "df = pd.read_csv('labels.csv')\n",
    "\n",
    "df['filename'] = df['filename'].apply(lambda fn: os.path.join('images', fn.strip()))\n",
    "\n",
    "filepaths = df['filename'].values\n",
    "labels = df['has_mite'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b27035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Fold 1 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 432ms/step - accuracy: 0.5624 - loss: 1.3326 - val_accuracy: 0.5705 - val_loss: 0.6899\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6297 - loss: 0.6707 - val_accuracy: 0.5705 - val_loss: 0.6832\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6297 - loss: 0.6709 - val_accuracy: 0.5705 - val_loss: 0.6938\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6297 - loss: 0.6711 - val_accuracy: 0.5705 - val_loss: 0.6834\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6297 - loss: 0.6743 - val_accuracy: 0.5705 - val_loss: 0.6832\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6297 - loss: 0.6659 - val_accuracy: 0.5705 - val_loss: 0.6850\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6297 - loss: 0.6628 - val_accuracy: 0.5705 - val_loss: 0.6835\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.6297 - loss: 0.6612 - val_accuracy: 0.5705 - val_loss: 0.6797\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 387ms/step - accuracy: 0.6297 - loss: 0.6531 - val_accuracy: 0.5705 - val_loss: 0.6789\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 360ms/step - accuracy: 0.6297 - loss: 0.6472 - val_accuracy: 0.5705 - val_loss: 0.6844\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5683 - loss: 0.6771\n",
      "✅ Fold 1 test accuracy: 0.5663\n",
      "\n",
      "🧪 Fold 2 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 419ms/step - accuracy: 0.5571 - loss: 0.9839 - val_accuracy: 0.5839 - val_loss: 0.6839\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.6370 - loss: 0.6682 - val_accuracy: 0.5839 - val_loss: 0.6795\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6370 - loss: 0.6795 - val_accuracy: 0.5839 - val_loss: 0.6793\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.6370 - loss: 0.6687 - val_accuracy: 0.5839 - val_loss: 0.6794\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6370 - loss: 0.6607 - val_accuracy: 0.5839 - val_loss: 0.6788\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6370 - loss: 0.6583 - val_accuracy: 0.5839 - val_loss: 0.6773\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.6370 - loss: 0.6604 - val_accuracy: 0.5839 - val_loss: 0.6765\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.6370 - loss: 0.6581 - val_accuracy: 0.5839 - val_loss: 0.6648\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6414 - loss: 0.6342 - val_accuracy: 0.5839 - val_loss: 0.6589\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6490 - loss: 0.5898 - val_accuracy: 0.6242 - val_loss: 0.6530\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6137 - loss: 0.6014\n",
      "✅ Fold 2 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 3 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.5936 - loss: 1.2439 - val_accuracy: 0.5973 - val_loss: 0.6745\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6232 - loss: 0.6841 - val_accuracy: 0.5973 - val_loss: 0.6814\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6232 - loss: 0.6809 - val_accuracy: 0.5973 - val_loss: 0.6757\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6232 - loss: 0.6888 - val_accuracy: 0.5973 - val_loss: 0.6726\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.6232 - loss: 0.6850 - val_accuracy: 0.5973 - val_loss: 0.6795\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6232 - loss: 0.6843 - val_accuracy: 0.5973 - val_loss: 0.6798\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6232 - loss: 0.6820 - val_accuracy: 0.5973 - val_loss: 0.6761\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6232 - loss: 0.6715 - val_accuracy: 0.5973 - val_loss: 0.6729\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6236 - loss: 0.6645 - val_accuracy: 0.5973 - val_loss: 0.6696\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6232 - loss: 0.6611 - val_accuracy: 0.5973 - val_loss: 0.6972\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5978 - loss: 0.7103\n",
      "✅ Fold 3 test accuracy: 0.5783\n",
      "\n",
      "🧪 Fold 4 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403ms/step - accuracy: 0.4759 - loss: 1.1159 - val_accuracy: 0.6107 - val_loss: 0.6702\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6247 - loss: 0.6768 - val_accuracy: 0.6107 - val_loss: 0.6741\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 445ms/step - accuracy: 0.6247 - loss: 0.6760 - val_accuracy: 0.6107 - val_loss: 0.6713\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6247 - loss: 0.6696 - val_accuracy: 0.6107 - val_loss: 0.6670\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6247 - loss: 0.6607 - val_accuracy: 0.6107 - val_loss: 0.6558\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6247 - loss: 0.6395 - val_accuracy: 0.6107 - val_loss: 0.6428\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6247 - loss: 0.6219 - val_accuracy: 0.6107 - val_loss: 0.6671\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6247 - loss: 0.6270 - val_accuracy: 0.6107 - val_loss: 0.6401\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6247 - loss: 0.5799 - val_accuracy: 0.6107 - val_loss: 0.6407\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 418ms/step - accuracy: 0.7037 - loss: 0.5666 - val_accuracy: 0.6913 - val_loss: 0.6549\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6829 - loss: 0.6158\n",
      "✅ Fold 4 test accuracy: 0.6627\n",
      "\n",
      "🧪 Fold 5 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 416ms/step - accuracy: 0.5957 - loss: 1.0961 - val_accuracy: 0.6040 - val_loss: 0.6727\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6342 - loss: 0.6825 - val_accuracy: 0.6040 - val_loss: 0.6825\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6342 - loss: 0.6774 - val_accuracy: 0.6040 - val_loss: 0.6722\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6342 - loss: 0.6643 - val_accuracy: 0.6040 - val_loss: 0.6719\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 421ms/step - accuracy: 0.6342 - loss: 0.6660 - val_accuracy: 0.6040 - val_loss: 0.6696\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 418ms/step - accuracy: 0.6342 - loss: 0.6579 - val_accuracy: 0.6040 - val_loss: 0.6519\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6503 - loss: 0.6468 - val_accuracy: 0.6040 - val_loss: 0.6521\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.6573 - loss: 0.6218 - val_accuracy: 0.7248 - val_loss: 0.6319\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6931 - loss: 0.5933 - val_accuracy: 0.7114 - val_loss: 0.6281\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 446ms/step - accuracy: 0.7357 - loss: 0.5514 - val_accuracy: 0.7114 - val_loss: 0.6311\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7701 - loss: 0.6137\n",
      "✅ Fold 5 test accuracy: 0.7590\n",
      "\n",
      "🧪 Fold 6 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 445ms/step - accuracy: 0.5919 - loss: 0.9619 - val_accuracy: 0.5906 - val_loss: 0.6772\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6331 - loss: 0.6835 - val_accuracy: 0.5906 - val_loss: 0.6821\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6331 - loss: 0.6828 - val_accuracy: 0.5906 - val_loss: 0.6766\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6331 - loss: 0.6709 - val_accuracy: 0.5906 - val_loss: 0.6811\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6331 - loss: 0.6688 - val_accuracy: 0.5906 - val_loss: 0.6763\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step - accuracy: 0.6331 - loss: 0.6601 - val_accuracy: 0.5906 - val_loss: 0.6776\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.6331 - loss: 0.6685 - val_accuracy: 0.5906 - val_loss: 0.6739\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step - accuracy: 0.6522 - loss: 0.6702 - val_accuracy: 0.5906 - val_loss: 0.6835\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 369ms/step - accuracy: 0.6331 - loss: 0.6714 - val_accuracy: 0.5906 - val_loss: 0.6734\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step - accuracy: 0.6305 - loss: 0.6523 - val_accuracy: 0.5906 - val_loss: 0.6644\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5978 - loss: 0.6601\n",
      "✅ Fold 6 test accuracy: 0.6098\n",
      "\n",
      "🧪 Fold 7 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.5842 - loss: 1.5752 - val_accuracy: 0.5570 - val_loss: 0.6938\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 359ms/step - accuracy: 0.6197 - loss: 0.6817 - val_accuracy: 0.5570 - val_loss: 0.6872\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step - accuracy: 0.6197 - loss: 0.6742 - val_accuracy: 0.5570 - val_loss: 0.6924\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 357ms/step - accuracy: 0.6197 - loss: 0.6675 - val_accuracy: 0.5570 - val_loss: 0.6880\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 358ms/step - accuracy: 0.6197 - loss: 0.6675 - val_accuracy: 0.5570 - val_loss: 0.6908\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 349ms/step - accuracy: 0.6197 - loss: 0.6670 - val_accuracy: 0.5570 - val_loss: 0.6875\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.6197 - loss: 0.6670 - val_accuracy: 0.5570 - val_loss: 0.6902\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.6197 - loss: 0.6649 - val_accuracy: 0.5570 - val_loss: 0.6883\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step - accuracy: 0.6197 - loss: 0.6645 - val_accuracy: 0.5570 - val_loss: 0.6939\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step - accuracy: 0.6197 - loss: 0.6716 - val_accuracy: 0.5570 - val_loss: 0.6972\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6813 - loss: 0.6302\n",
      "✅ Fold 7 test accuracy: 0.6829\n",
      "\n",
      "🧪 Fold 8 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 380ms/step - accuracy: 0.6220 - loss: 0.8070 - val_accuracy: 0.5705 - val_loss: 0.6812\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 425ms/step - accuracy: 0.6403 - loss: 0.6672 - val_accuracy: 0.5705 - val_loss: 0.6832\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6403 - loss: 0.6666 - val_accuracy: 0.5705 - val_loss: 0.6848\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6403 - loss: 0.6681 - val_accuracy: 0.5705 - val_loss: 0.6858\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.6403 - loss: 0.6672 - val_accuracy: 0.5705 - val_loss: 0.6791\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6403 - loss: 0.6599 - val_accuracy: 0.5705 - val_loss: 0.6762\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6403 - loss: 0.6527 - val_accuracy: 0.5705 - val_loss: 0.6855\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6188 - loss: 0.6447 - val_accuracy: 0.5705 - val_loss: 0.6843\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6543 - loss: 0.6377 - val_accuracy: 0.5705 - val_loss: 0.6835\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6800 - loss: 0.5945 - val_accuracy: 0.6242 - val_loss: 0.6995\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5996 - loss: 0.7478\n",
      "✅ Fold 8 test accuracy: 0.5976\n",
      "\n",
      "🧪 Fold 9 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.5854 - loss: 1.0543 - val_accuracy: 0.5570 - val_loss: 0.6873\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6332 - loss: 0.6736 - val_accuracy: 0.5570 - val_loss: 0.6940\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6332 - loss: 0.6630 - val_accuracy: 0.5570 - val_loss: 0.6887\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6332 - loss: 0.6625 - val_accuracy: 0.5570 - val_loss: 0.6907\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6332 - loss: 0.6555 - val_accuracy: 0.5570 - val_loss: 0.6904\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6045 - loss: 0.6524 - val_accuracy: 0.5570 - val_loss: 0.7117\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.6510 - loss: 0.6297 - val_accuracy: 0.5839 - val_loss: 0.6659\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.6457 - loss: 0.6038 - val_accuracy: 0.5772 - val_loss: 0.7408\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6981 - loss: 0.5594 - val_accuracy: 0.6040 - val_loss: 0.7618\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.7503 - loss: 0.5198 - val_accuracy: 0.6711 - val_loss: 0.6572\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6623 - loss: 0.5991\n",
      "✅ Fold 9 test accuracy: 0.7073\n",
      "\n",
      "🧪 Fold 10 -----------------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.6135 - loss: 1.0490 - val_accuracy: 0.5839 - val_loss: 0.6798\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6173 - loss: 0.6779 - val_accuracy: 0.5839 - val_loss: 0.6790\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6173 - loss: 0.6776 - val_accuracy: 0.5839 - val_loss: 0.6785\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6173 - loss: 0.6728 - val_accuracy: 0.5839 - val_loss: 0.6793\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6173 - loss: 0.6702 - val_accuracy: 0.5839 - val_loss: 0.6774\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.6173 - loss: 0.6627 - val_accuracy: 0.5839 - val_loss: 0.6780\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6144 - loss: 0.6461 - val_accuracy: 0.5839 - val_loss: 0.6659\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 395ms/step - accuracy: 0.6173 - loss: 0.6224 - val_accuracy: 0.5839 - val_loss: 0.6574\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.6571 - loss: 0.5844 - val_accuracy: 0.6376 - val_loss: 0.6815\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.7204 - loss: 0.5490 - val_accuracy: 0.6779 - val_loss: 0.6825\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7892 - loss: 0.4726\n",
      "✅ Fold 10 test accuracy: 0.8049\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 3: K-Fold Cross-Validation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# # define it once (you can tweak patience, monitor, etc. as you like)\n",
    "# earlystop = EarlyStopping(\n",
    "#     monitor='val_loss',        # watch validation loss\n",
    "#     patience=5,               # stop if no improvement for 10 epochs\n",
    "#     restore_best_weights=True  # roll back to the best weights seen\n",
    "# )\n",
    "\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "all_test_accuracies = []\n",
    "\n",
    "for trainval_index, test_index in kf.split(filepaths):\n",
    "    print(f\"\\n🧪 Fold {fold} -----------------------------\")\n",
    "\n",
    "    # Split into trainval and test\n",
    "    X_trainval, X_test = filepaths[trainval_index], filepaths[test_index]\n",
    "    y_trainval, y_test = labels[trainval_index], labels[test_index]\n",
    "\n",
    "    # Further split trainval into train and val (e.g. 80/20)\n",
    "    val_split = int(0.8 * len(X_trainval))\n",
    "    X_train, X_val = X_trainval[:val_split], X_trainval[val_split:]\n",
    "    y_train, y_val = y_trainval[:val_split], y_trainval[val_split:]\n",
    "\n",
    "\n",
    "    def preprocess(paths, labels):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "        def load_img(path, label):\n",
    "            img = tf.io.read_file(path)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, [224, 224])\n",
    "            img = img / 255.0\n",
    "            return img, label\n",
    "\n",
    "        return ds.map(load_img).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = preprocess(X_train, y_train)\n",
    "    val_ds = preprocess(X_val, y_val)\n",
    "    test_ds = preprocess(X_test, y_test)\n",
    "\n",
    "\n",
    "    # Build a fresh model for each fold\n",
    "    def create_model():\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=(224, 224, 3)),\n",
    "            layers.Conv2D(32, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "    # # Train\n",
    "    # model.fit(train_ds, validation_data=val_ds, epochs=100, verbose=1)\n",
    "\n",
    "    # Train with early stopping\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=10,            # generous upper bound\n",
    "        # callbacks=[earlystop], # ← here!\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    all_test_accuracies.append(test_acc)\n",
    "    print(f\"✅ Fold {fold} test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266fba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 10-Fold Test Accuracy: 0.6571 ± 0.0766\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 4: Final Evaluation\n",
    "mean_acc = np.mean(all_test_accuracies)\n",
    "std_acc = np.std(all_test_accuracies)\n",
    "print(f\"\\n📊 {k}-Fold Test Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
