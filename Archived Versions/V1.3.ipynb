{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae6385",
   "metadata": {},
   "source": [
    "Varroa Mite Detection 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9629b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 1: Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f75b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 2: Load Data and Preprocess\n",
    "\n",
    "df = pd.read_csv('labels.csv')\n",
    "\n",
    "df['filename'] = df['filename'].apply(lambda fn: os.path.join('images', fn.strip()))\n",
    "\n",
    "filepaths = df['filename'].values\n",
    "labels = df['has_mite'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b27035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Fold 1 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 441ms/step - accuracy: 0.5865 - loss: 1.0372 - val_accuracy: 0.6061 - val_loss: 0.6788\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 409ms/step - accuracy: 0.6189 - loss: 0.6779 - val_accuracy: 0.6061 - val_loss: 0.6834\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 422ms/step - accuracy: 0.6189 - loss: 0.6788 - val_accuracy: 0.6061 - val_loss: 0.6721\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 410ms/step - accuracy: 0.6189 - loss: 0.6712 - val_accuracy: 0.6061 - val_loss: 0.6747\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.6189 - loss: 0.6692 - val_accuracy: 0.6061 - val_loss: 0.6720\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 431ms/step - accuracy: 0.6189 - loss: 0.6696 - val_accuracy: 0.6061 - val_loss: 0.6759\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 408ms/step - accuracy: 0.6189 - loss: 0.6669 - val_accuracy: 0.6061 - val_loss: 0.6817\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 439ms/step - accuracy: 0.6189 - loss: 0.6565 - val_accuracy: 0.6061 - val_loss: 0.6916\n",
      "🏁 Best epoch for Fold 1: 5\n",
      "✅ Fold 1 test accuracy: 0.6000\n",
      "\n",
      "🧪 Fold 2 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6218 - loss: 0.9539 - val_accuracy: 0.5303 - val_loss: 0.6935\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.6414 - loss: 0.6862 - val_accuracy: 0.5303 - val_loss: 0.6929\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 449ms/step - accuracy: 0.6414 - loss: 0.6787 - val_accuracy: 0.5303 - val_loss: 0.6933\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 427ms/step - accuracy: 0.6414 - loss: 0.6615 - val_accuracy: 0.5303 - val_loss: 0.7052\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 436ms/step - accuracy: 0.6414 - loss: 0.6518 - val_accuracy: 0.5303 - val_loss: 0.7017\n",
      "🏁 Best epoch for Fold 2: 2\n",
      "✅ Fold 2 test accuracy: 0.6000\n",
      "\n",
      "🧪 Fold 3 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 386ms/step - accuracy: 0.5626 - loss: 0.7942 - val_accuracy: 0.6136 - val_loss: 0.6714\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 405ms/step - accuracy: 0.6166 - loss: 0.6725 - val_accuracy: 0.6136 - val_loss: 0.6675\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 441ms/step - accuracy: 0.6166 - loss: 0.6640 - val_accuracy: 0.6136 - val_loss: 0.6662\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 388ms/step - accuracy: 0.6166 - loss: 0.6609 - val_accuracy: 0.6136 - val_loss: 0.6611\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.6134 - loss: 0.6495 - val_accuracy: 0.6136 - val_loss: 0.6515\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 374ms/step - accuracy: 0.6166 - loss: 0.6226 - val_accuracy: 0.6061 - val_loss: 0.6398\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.6197 - loss: 0.6122 - val_accuracy: 0.6136 - val_loss: 0.6331\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 367ms/step - accuracy: 0.6587 - loss: 0.5560 - val_accuracy: 0.6364 - val_loss: 0.6485\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.7396 - loss: 0.5260 - val_accuracy: 0.6591 - val_loss: 0.6593\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 381ms/step - accuracy: 0.7793 - loss: 0.4877 - val_accuracy: 0.6212 - val_loss: 0.6654\n",
      "🏁 Best epoch for Fold 3: 7\n",
      "✅ Fold 3 test accuracy: 0.6364\n",
      "\n",
      "🧪 Fold 4 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 439ms/step - accuracy: 0.5045 - loss: 0.8794 - val_accuracy: 0.5606 - val_loss: 0.6953\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 411ms/step - accuracy: 0.6343 - loss: 0.6794 - val_accuracy: 0.5606 - val_loss: 0.6858\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 397ms/step - accuracy: 0.6343 - loss: 0.6773 - val_accuracy: 0.5606 - val_loss: 0.6863\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.6343 - loss: 0.6720 - val_accuracy: 0.5606 - val_loss: 0.6857\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 427ms/step - accuracy: 0.6343 - loss: 0.6674 - val_accuracy: 0.5606 - val_loss: 0.6880\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 426ms/step - accuracy: 0.6343 - loss: 0.6615 - val_accuracy: 0.5606 - val_loss: 0.6850\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 401ms/step - accuracy: 0.6343 - loss: 0.6634 - val_accuracy: 0.5606 - val_loss: 0.7001\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 412ms/step - accuracy: 0.6146 - loss: 0.6460 - val_accuracy: 0.5606 - val_loss: 0.6905\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 394ms/step - accuracy: 0.6595 - loss: 0.6498 - val_accuracy: 0.5758 - val_loss: 0.6734\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 396ms/step - accuracy: 0.6800 - loss: 0.6221 - val_accuracy: 0.5909 - val_loss: 0.6544\n",
      "Epoch 11/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 396ms/step - accuracy: 0.6887 - loss: 0.5741 - val_accuracy: 0.6818 - val_loss: 0.6925\n",
      "Epoch 12/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.7761 - loss: 0.5164 - val_accuracy: 0.6742 - val_loss: 0.8007\n",
      "Epoch 13/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 398ms/step - accuracy: 0.7762 - loss: 0.4955 - val_accuracy: 0.6288 - val_loss: 0.6959\n",
      "🏁 Best epoch for Fold 4: 10\n",
      "✅ Fold 4 test accuracy: 0.6485\n",
      "\n",
      "🧪 Fold 5 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.5449 - loss: 1.0362 - val_accuracy: 0.5985 - val_loss: 0.6746\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 406ms/step - accuracy: 0.6265 - loss: 0.6877 - val_accuracy: 0.5985 - val_loss: 0.6858\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6265 - loss: 0.6815 - val_accuracy: 0.5985 - val_loss: 0.6736\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 401ms/step - accuracy: 0.6265 - loss: 0.6742 - val_accuracy: 0.5985 - val_loss: 0.6777\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 391ms/step - accuracy: 0.6265 - loss: 0.6718 - val_accuracy: 0.5985 - val_loss: 0.6730\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.6265 - loss: 0.6666 - val_accuracy: 0.5985 - val_loss: 0.6734\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.6265 - loss: 0.6659 - val_accuracy: 0.5985 - val_loss: 0.6698\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 398ms/step - accuracy: 0.6265 - loss: 0.6731 - val_accuracy: 0.5985 - val_loss: 0.6739\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 405ms/step - accuracy: 0.6265 - loss: 0.6620 - val_accuracy: 0.5985 - val_loss: 0.6621\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 397ms/step - accuracy: 0.6265 - loss: 0.6437 - val_accuracy: 0.5985 - val_loss: 0.6657\n",
      "Epoch 11/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.6265 - loss: 0.6405 - val_accuracy: 0.5985 - val_loss: 0.6474\n",
      "Epoch 12/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 395ms/step - accuracy: 0.6265 - loss: 0.6170 - val_accuracy: 0.5985 - val_loss: 0.6654\n",
      "Epoch 13/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 401ms/step - accuracy: 0.6288 - loss: 0.5964 - val_accuracy: 0.6288 - val_loss: 0.6312\n",
      "Epoch 14/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step - accuracy: 0.6904 - loss: 0.5893 - val_accuracy: 0.5985 - val_loss: 0.6587\n",
      "Epoch 15/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 402ms/step - accuracy: 0.6838 - loss: 0.5766 - val_accuracy: 0.5758 - val_loss: 0.6474\n",
      "Epoch 16/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 389ms/step - accuracy: 0.7224 - loss: 0.5275 - val_accuracy: 0.6061 - val_loss: 0.6842\n",
      "🏁 Best epoch for Fold 5: 13\n",
      "✅ Fold 5 test accuracy: 0.6970\n",
      "\n",
      "📌 Mean optimal epoch across folds: 7\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 3: K-Fold Cross-Validation\n",
    "\n",
    "# Early stopping callback\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    min_delta=1e-4,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "k = 5  # Number of folds\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "all_test_accuracies = []\n",
    "best_epochs = []\n",
    "\n",
    "# Model creation function\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(224, 224, 3)),\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(paths, labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def load_img(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = img / 255.0\n",
    "        return img, label\n",
    "\n",
    "    return ds.map(load_img).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for trainval_index, test_index in skf.split(filepaths, labels):\n",
    "    print(f\"\\n🧪 Fold {fold} -----------------------------\")\n",
    "\n",
    "    # Split into trainval and test\n",
    "    X_trainval, X_test = filepaths[trainval_index], filepaths[test_index]\n",
    "    y_trainval, y_test = labels[trainval_index], labels[test_index]\n",
    "\n",
    "    # Further split trainval into train and val (e.g. 80/20)\n",
    "    val_split = int(0.8 * len(X_trainval))\n",
    "    X_train, X_val = X_trainval[:val_split], X_trainval[val_split:]\n",
    "    y_train, y_val = y_trainval[:val_split], y_trainval[val_split:]\n",
    "\n",
    "\n",
    "    # Preprocess each split\n",
    "    train_ds = preprocess(X_train, y_train)\n",
    "    val_ds = preprocess(X_val, y_val)\n",
    "    test_ds = preprocess(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # Train model with early stopping\n",
    "    model = create_model()\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,\n",
    "        callbacks=[earlystop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Record best epoch (smallest val_loss)\n",
    "    best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "    best_epochs.append(best_epoch)\n",
    "    print(f\"🏁 Best epoch for Fold {fold}: {best_epoch}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
    "    all_test_accuracies.append(test_acc)\n",
    "    print(f\"✅ Fold {fold} test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Calculate mean best epoch\n",
    "ep_mean = int(np.round(np.mean(best_epochs)))\n",
    "print(f\"\\n📌 Mean optimal epoch across folds: {ep_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1440c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 402ms/step - accuracy: 0.5324 - loss: 0.8620\n",
      "Epoch 2/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6309 - loss: 0.6829\n",
      "Epoch 3/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 383ms/step - accuracy: 0.6125 - loss: 0.6782\n",
      "Epoch 4/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.6309 - loss: 0.6915\n",
      "Epoch 5/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 387ms/step - accuracy: 0.6309 - loss: 0.6899\n",
      "Epoch 6/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 386ms/step - accuracy: 0.6309 - loss: 0.6882\n",
      "Epoch 7/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - accuracy: 0.6309 - loss: 0.6866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x12d09784bc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell Block 4: Final Model Training on data again, but for ep_mean Epochs (no validation needed)\n",
    "\n",
    "## NOTE: THIS IS NOT TESTING ON HIDDEN DATA - IT WAS TECHNICALLY SEEN IN THE k-FOLD.\n",
    "## CAN TALK ABOUT THIS TO AYUSHMAN\n",
    "\n",
    "# Split all data into 80% train and 20% test\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    filepaths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Use your same preprocess function\n",
    "train_final_ds = preprocess(X_train_final, y_train_final)\n",
    "test_final_ds = preprocess(X_test_final, y_test_final)\n",
    "\n",
    "# Create and train model with ep_mean\n",
    "final_model = create_model()\n",
    "final_model.fit(\n",
    "    train_final_ds,\n",
    "    epochs=ep_mean,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "266fba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 5-Fold Test Accuracy: 0.6364 ± 0.0360\n",
      "🏁 Final model test accuracy (trained on 80% for 7 epochs): 0.6000\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 5: Final Evaluation\n",
    "\n",
    "# Evaluate final model on the 20% test set\n",
    "final_test_loss, final_test_acc = final_model.evaluate(test_final_ds, verbose=0)\n",
    "\n",
    "# Report both results\n",
    "print(f\"\\n📊 {k}-Fold Test Accuracy: {np.mean(all_test_accuracies):.4f} ± {np.std(all_test_accuracies):.4f}\")\n",
    "print(f\"🏁 Final model test accuracy (trained on 80% for {ep_mean} epochs): {final_test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
