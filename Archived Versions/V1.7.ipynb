{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae6385",
   "metadata": {},
   "source": [
    "Varroa Mite Detection 1.7 Blue Shift the Images No Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9629b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 1: Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f75b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 2: Load Data and Preprocess\n",
    "\n",
    "df = pd.read_csv('labels_augmented.csv')\n",
    "\n",
    "df['filename'] = df['filename'].apply(lambda fn: os.path.join('rotations_flips', fn.strip()))\n",
    "\n",
    "filepaths = df['filename'].values\n",
    "labels = df['has_mite'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b27035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª Fold 1 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 448ms/step - accuracy: 0.6076 - loss: 0.7543 - val_accuracy: 0.5922 - val_loss: 0.6772\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 428ms/step - accuracy: 0.6091 - loss: 0.6753 - val_accuracy: 0.5922 - val_loss: 0.6768\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 467ms/step - accuracy: 0.6033 - loss: 0.6755 - val_accuracy: 0.5922 - val_loss: 0.6804\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 426ms/step - accuracy: 0.6090 - loss: 0.6777 - val_accuracy: 0.5922 - val_loss: 0.6804\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 399ms/step - accuracy: 0.6017 - loss: 0.6750 - val_accuracy: 0.5922 - val_loss: 0.6876\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 394ms/step - accuracy: 0.6091 - loss: 0.6855 - val_accuracy: 0.5922 - val_loss: 0.6845\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 403ms/step - accuracy: 0.6091 - loss: 0.6819 - val_accuracy: 0.5922 - val_loss: 0.6822\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 404ms/step - accuracy: 0.6091 - loss: 0.6791 - val_accuracy: 0.5922 - val_loss: 0.6804\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 412ms/step - accuracy: 0.6091 - loss: 0.6769 - val_accuracy: 0.5922 - val_loss: 0.6792\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 404ms/step - accuracy: 0.6091 - loss: 0.6753 - val_accuracy: 0.5922 - val_loss: 0.6782\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 407ms/step - accuracy: 0.6091 - loss: 0.6740 - val_accuracy: 0.5922 - val_loss: 0.6775\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 407ms/step - accuracy: 0.6091 - loss: 0.6729 - val_accuracy: 0.5922 - val_loss: 0.6770\n",
      "ğŸ Best epoch for Fold 1: 2\n",
      "âœ… Fold 1 test accuracy: 0.6029\n",
      "\n",
      "ğŸ§ª Fold 2 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.5798 - loss: 0.7412 - val_accuracy: 0.5868 - val_loss: 0.6827\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 405ms/step - accuracy: 0.6074 - loss: 0.6708 - val_accuracy: 0.5868 - val_loss: 0.6799\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 408ms/step - accuracy: 0.6182 - loss: 0.6712 - val_accuracy: 0.5868 - val_loss: 0.6890\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 410ms/step - accuracy: 0.6182 - loss: 0.6862 - val_accuracy: 0.5868 - val_loss: 0.6858\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 414ms/step - accuracy: 0.6182 - loss: 0.6818 - val_accuracy: 0.5868 - val_loss: 0.6834\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 426ms/step - accuracy: 0.6182 - loss: 0.6783 - val_accuracy: 0.5868 - val_loss: 0.6817\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 375ms/step - accuracy: 0.6182 - loss: 0.6756 - val_accuracy: 0.5868 - val_loss: 0.6805\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 332ms/step - accuracy: 0.6182 - loss: 0.6735 - val_accuracy: 0.5868 - val_loss: 0.6796\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 332ms/step - accuracy: 0.6182 - loss: 0.6719 - val_accuracy: 0.5868 - val_loss: 0.6790\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 332ms/step - accuracy: 0.6182 - loss: 0.6706 - val_accuracy: 0.5868 - val_loss: 0.6786\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 330ms/step - accuracy: 0.6182 - loss: 0.6695 - val_accuracy: 0.5868 - val_loss: 0.6783\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 337ms/step - accuracy: 0.6182 - loss: 0.6687 - val_accuracy: 0.5868 - val_loss: 0.6781\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 337ms/step - accuracy: 0.6182 - loss: 0.6681 - val_accuracy: 0.5868 - val_loss: 0.6780\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 332ms/step - accuracy: 0.6182 - loss: 0.6675 - val_accuracy: 0.5868 - val_loss: 0.6780\n",
      "Epoch 15/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 335ms/step - accuracy: 0.6182 - loss: 0.6671 - val_accuracy: 0.5868 - val_loss: 0.6780\n",
      "Epoch 16/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 335ms/step - accuracy: 0.6182 - loss: 0.6668 - val_accuracy: 0.5868 - val_loss: 0.6780\n",
      "Epoch 17/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 334ms/step - accuracy: 0.6182 - loss: 0.6665 - val_accuracy: 0.5868 - val_loss: 0.6781\n",
      "Epoch 18/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 331ms/step - accuracy: 0.6182 - loss: 0.6663 - val_accuracy: 0.5868 - val_loss: 0.6781\n",
      "Epoch 19/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 345ms/step - accuracy: 0.6182 - loss: 0.6661 - val_accuracy: 0.5868 - val_loss: 0.6782\n",
      "Epoch 20/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 336ms/step - accuracy: 0.6182 - loss: 0.6660 - val_accuracy: 0.5868 - val_loss: 0.6782\n",
      "Epoch 21/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 335ms/step - accuracy: 0.6182 - loss: 0.6659 - val_accuracy: 0.5868 - val_loss: 0.6783\n",
      "Epoch 22/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 332ms/step - accuracy: 0.6182 - loss: 0.6658 - val_accuracy: 0.5868 - val_loss: 0.6783\n",
      "Epoch 23/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 333ms/step - accuracy: 0.6182 - loss: 0.6657 - val_accuracy: 0.5868 - val_loss: 0.6784\n",
      "Epoch 24/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 332ms/step - accuracy: 0.6182 - loss: 0.6657 - val_accuracy: 0.5868 - val_loss: 0.6784\n",
      "ğŸ Best epoch for Fold 2: 14\n",
      "âœ… Fold 2 test accuracy: 0.6029\n",
      "\n",
      "ğŸ§ª Fold 3 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 334ms/step - accuracy: 0.6092 - loss: 0.7538 - val_accuracy: 0.5828 - val_loss: 0.6824\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 328ms/step - accuracy: 0.6173 - loss: 0.6718 - val_accuracy: 0.5828 - val_loss: 0.6790\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.5974 - loss: 0.6835 - val_accuracy: 0.5828 - val_loss: 0.6740\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.6173 - loss: 0.6493 - val_accuracy: 0.5828 - val_loss: 0.6385\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6173 - loss: 0.6010 - val_accuracy: 0.5828 - val_loss: 0.6355\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.6195 - loss: 0.5714 - val_accuracy: 0.7820 - val_loss: 0.5933\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 326ms/step - accuracy: 0.8034 - loss: 0.5263 - val_accuracy: 0.6904 - val_loss: 0.6248\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.7966 - loss: 0.5154 - val_accuracy: 0.7887 - val_loss: 0.5673\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.8249 - loss: 0.4815 - val_accuracy: 0.6958 - val_loss: 0.6110\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.7940 - loss: 0.4753 - val_accuracy: 0.7968 - val_loss: 0.5190\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.8306 - loss: 0.3950 - val_accuracy: 0.7779 - val_loss: 0.5052\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.8422 - loss: 0.3737 - val_accuracy: 0.7645 - val_loss: 0.5590\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.8240 - loss: 0.4127 - val_accuracy: 0.8116 - val_loss: 0.4784\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.8617 - loss: 0.3287 - val_accuracy: 0.8223 - val_loss: 0.4509\n",
      "Epoch 15/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.8689 - loss: 0.3150 - val_accuracy: 0.8223 - val_loss: 0.4359\n",
      "Epoch 16/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.8805 - loss: 0.3011 - val_accuracy: 0.8237 - val_loss: 0.4251\n",
      "Epoch 17/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.8779 - loss: 0.2909 - val_accuracy: 0.8156 - val_loss: 0.4648\n",
      "Epoch 18/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.8784 - loss: 0.2823 - val_accuracy: 0.7900 - val_loss: 0.5528\n",
      "Epoch 19/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.8421 - loss: 0.3339 - val_accuracy: 0.8129 - val_loss: 0.4752\n",
      "Epoch 20/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.8629 - loss: 0.3169 - val_accuracy: 0.8156 - val_loss: 0.5938\n",
      "Epoch 21/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.8656 - loss: 0.3178 - val_accuracy: 0.8223 - val_loss: 0.4848\n",
      "Epoch 22/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.8676 - loss: 0.2920 - val_accuracy: 0.7941 - val_loss: 0.5654\n",
      "Epoch 23/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.8705 - loss: 0.2832 - val_accuracy: 0.8089 - val_loss: 0.4881\n",
      "Epoch 24/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.8884 - loss: 0.2541 - val_accuracy: 0.8264 - val_loss: 0.4781\n",
      "Epoch 25/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.8872 - loss: 0.2578 - val_accuracy: 0.8129 - val_loss: 0.5629\n",
      "Epoch 26/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.8986 - loss: 0.2372 - val_accuracy: 0.7995 - val_loss: 0.5975\n",
      "ğŸ Best epoch for Fold 3: 16\n",
      "âœ… Fold 3 test accuracy: 0.8450\n",
      "\n",
      "ğŸ§ª Fold 4 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 324ms/step - accuracy: 0.5949 - loss: 0.8021 - val_accuracy: 0.5814 - val_loss: 0.6917\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6183 - loss: 0.6898 - val_accuracy: 0.5814 - val_loss: 0.6882\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.6183 - loss: 0.6761 - val_accuracy: 0.5814 - val_loss: 0.6789\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6183 - loss: 0.6723 - val_accuracy: 0.5814 - val_loss: 0.6818\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6183 - loss: 0.6803 - val_accuracy: 0.5814 - val_loss: 0.6856\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6183 - loss: 0.6807 - val_accuracy: 0.5814 - val_loss: 0.6837\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6183 - loss: 0.6775 - val_accuracy: 0.5814 - val_loss: 0.6823\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6183 - loss: 0.6749 - val_accuracy: 0.5814 - val_loss: 0.6813\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6183 - loss: 0.6730 - val_accuracy: 0.5814 - val_loss: 0.6807\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6183 - loss: 0.6714 - val_accuracy: 0.5814 - val_loss: 0.6803\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6183 - loss: 0.6702 - val_accuracy: 0.5814 - val_loss: 0.6800\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6183 - loss: 0.6692 - val_accuracy: 0.5814 - val_loss: 0.6799\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6183 - loss: 0.6684 - val_accuracy: 0.5814 - val_loss: 0.6798\n",
      "ğŸ Best epoch for Fold 4: 3\n",
      "âœ… Fold 4 test accuracy: 0.6029\n",
      "\n",
      "ğŸ§ª Fold 5 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - accuracy: 0.5732 - loss: 0.7111 - val_accuracy: 0.5922 - val_loss: 0.6887\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6099 - loss: 0.6785 - val_accuracy: 0.5922 - val_loss: 0.6793\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6084 - loss: 0.6753 - val_accuracy: 0.5922 - val_loss: 0.6771\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6099 - loss: 0.6747 - val_accuracy: 0.5922 - val_loss: 0.6762\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6010 - loss: 0.6731 - val_accuracy: 0.5922 - val_loss: 0.6787\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.6099 - loss: 0.6747 - val_accuracy: 0.5922 - val_loss: 0.6847\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6099 - loss: 0.6820 - val_accuracy: 0.5922 - val_loss: 0.6821\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6099 - loss: 0.6788 - val_accuracy: 0.5922 - val_loss: 0.6802\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.6099 - loss: 0.6764 - val_accuracy: 0.5922 - val_loss: 0.6788\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6099 - loss: 0.6746 - val_accuracy: 0.5922 - val_loss: 0.6779\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6099 - loss: 0.6732 - val_accuracy: 0.5922 - val_loss: 0.6772\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6099 - loss: 0.6722 - val_accuracy: 0.5922 - val_loss: 0.6768\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6099 - loss: 0.6714 - val_accuracy: 0.5922 - val_loss: 0.6765\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6099 - loss: 0.6709 - val_accuracy: 0.5922 - val_loss: 0.6763\n",
      "ğŸ Best epoch for Fold 5: 4\n",
      "âœ… Fold 5 test accuracy: 0.6029\n",
      "\n",
      "ğŸ§ª Fold 6 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - accuracy: 0.5977 - loss: 0.7550 - val_accuracy: 0.5774 - val_loss: 0.6909\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6124 - loss: 0.6780 - val_accuracy: 0.5774 - val_loss: 0.6847\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6106 - loss: 0.6758 - val_accuracy: 0.5774 - val_loss: 0.6897\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6100 - loss: 0.6749 - val_accuracy: 0.5774 - val_loss: 0.6894\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6124 - loss: 0.6863 - val_accuracy: 0.5774 - val_loss: 0.6863\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6124 - loss: 0.6816 - val_accuracy: 0.5774 - val_loss: 0.6842\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6124 - loss: 0.6781 - val_accuracy: 0.5774 - val_loss: 0.6828\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6124 - loss: 0.6755 - val_accuracy: 0.5774 - val_loss: 0.6820\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6124 - loss: 0.6736 - val_accuracy: 0.5774 - val_loss: 0.6815\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6124 - loss: 0.6721 - val_accuracy: 0.5774 - val_loss: 0.6812\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6124 - loss: 0.6710 - val_accuracy: 0.5774 - val_loss: 0.6811\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6124 - loss: 0.6702 - val_accuracy: 0.5774 - val_loss: 0.6812\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6124 - loss: 0.6696 - val_accuracy: 0.5774 - val_loss: 0.6812\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.6124 - loss: 0.6692 - val_accuracy: 0.5774 - val_loss: 0.6814\n",
      "Epoch 15/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6124 - loss: 0.6688 - val_accuracy: 0.5774 - val_loss: 0.6815\n",
      "Epoch 16/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6124 - loss: 0.6686 - val_accuracy: 0.5774 - val_loss: 0.6817\n",
      "Epoch 17/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6124 - loss: 0.6684 - val_accuracy: 0.5774 - val_loss: 0.6819\n",
      "Epoch 18/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 327ms/step - accuracy: 0.6124 - loss: 0.6682 - val_accuracy: 0.5774 - val_loss: 0.6820\n",
      "Epoch 19/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 330ms/step - accuracy: 0.6124 - loss: 0.6681 - val_accuracy: 0.5774 - val_loss: 0.6822\n",
      "Epoch 20/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6124 - loss: 0.6681 - val_accuracy: 0.5774 - val_loss: 0.6823\n",
      "Epoch 21/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6124 - loss: 0.6680 - val_accuracy: 0.5774 - val_loss: 0.6824\n",
      "ğŸ Best epoch for Fold 6: 11\n",
      "âœ… Fold 6 test accuracy: 0.6019\n",
      "\n",
      "ğŸ§ª Fold 7 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 324ms/step - accuracy: 0.5825 - loss: 0.8554 - val_accuracy: 0.5882 - val_loss: 0.6813\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6191 - loss: 0.6705 - val_accuracy: 0.5882 - val_loss: 0.6767\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6193 - loss: 0.6618 - val_accuracy: 0.5882 - val_loss: 0.6830\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6003 - loss: 0.6707 - val_accuracy: 0.5882 - val_loss: 0.6797\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6191 - loss: 0.6712 - val_accuracy: 0.5882 - val_loss: 0.6776\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.6191 - loss: 0.6682 - val_accuracy: 0.5882 - val_loss: 0.6775\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6191 - loss: 0.6673 - val_accuracy: 0.5882 - val_loss: 0.6775\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6191 - loss: 0.6671 - val_accuracy: 0.5882 - val_loss: 0.6776\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6191 - loss: 0.6669 - val_accuracy: 0.5882 - val_loss: 0.6776\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6191 - loss: 0.6668 - val_accuracy: 0.5882 - val_loss: 0.6776\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6191 - loss: 0.6667 - val_accuracy: 0.5882 - val_loss: 0.6776\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 321ms/step - accuracy: 0.6191 - loss: 0.6667 - val_accuracy: 0.5882 - val_loss: 0.6776\n",
      "ğŸ Best epoch for Fold 7: 2\n",
      "âœ… Fold 7 test accuracy: 0.6019\n",
      "\n",
      "ğŸ§ª Fold 8 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - accuracy: 0.5975 - loss: 0.8851 - val_accuracy: 0.5908 - val_loss: 0.6771\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6148 - loss: 0.6717 - val_accuracy: 0.5908 - val_loss: 0.6778\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6148 - loss: 0.6740 - val_accuracy: 0.5908 - val_loss: 0.6771\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6148 - loss: 0.6718 - val_accuracy: 0.5908 - val_loss: 0.6775\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6111 - loss: 0.6722 - val_accuracy: 0.5908 - val_loss: 0.6771\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.6148 - loss: 0.6724 - val_accuracy: 0.5908 - val_loss: 0.6764\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6148 - loss: 0.6717 - val_accuracy: 0.5908 - val_loss: 0.6762\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6148 - loss: 0.6715 - val_accuracy: 0.5908 - val_loss: 0.6769\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6148 - loss: 0.6719 - val_accuracy: 0.5908 - val_loss: 0.6843\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6148 - loss: 0.6754 - val_accuracy: 0.5908 - val_loss: 0.6827\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 329ms/step - accuracy: 0.6148 - loss: 0.6756 - val_accuracy: 0.5908 - val_loss: 0.6826\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 329ms/step - accuracy: 0.6148 - loss: 0.6785 - val_accuracy: 0.5908 - val_loss: 0.6807\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6148 - loss: 0.6761 - val_accuracy: 0.5908 - val_loss: 0.6788\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6148 - loss: 0.6709 - val_accuracy: 0.5908 - val_loss: 0.6768\n",
      "Epoch 15/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6148 - loss: 0.6706 - val_accuracy: 0.5908 - val_loss: 0.6787\n",
      "Epoch 16/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 322ms/step - accuracy: 0.6148 - loss: 0.6731 - val_accuracy: 0.5908 - val_loss: 0.6782\n",
      "Epoch 17/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.6148 - loss: 0.6720 - val_accuracy: 0.5908 - val_loss: 0.6776\n",
      "ğŸ Best epoch for Fold 8: 7\n",
      "âœ… Fold 8 test accuracy: 0.6019\n",
      "\n",
      "ğŸ§ª Fold 9 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 324ms/step - accuracy: 0.5973 - loss: 0.8045 - val_accuracy: 0.5922 - val_loss: 0.6771\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6118 - loss: 0.6723 - val_accuracy: 0.5922 - val_loss: 0.6758\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6132 - loss: 0.6715 - val_accuracy: 0.5922 - val_loss: 0.6762\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6206 - loss: 0.6725 - val_accuracy: 0.5922 - val_loss: 0.6807\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6178 - loss: 0.6708 - val_accuracy: 0.5989 - val_loss: 0.6597\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6616 - loss: 0.6344 - val_accuracy: 0.7066 - val_loss: 0.6133\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.7178 - loss: 0.5795 - val_accuracy: 0.7160 - val_loss: 0.5846\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.7753 - loss: 0.5099 - val_accuracy: 0.7510 - val_loss: 0.5295\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.7770 - loss: 0.5010 - val_accuracy: 0.7362 - val_loss: 0.5562\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.8044 - loss: 0.4725 - val_accuracy: 0.7201 - val_loss: 0.5780\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 330ms/step - accuracy: 0.8100 - loss: 0.4405 - val_accuracy: 0.7699 - val_loss: 0.5054\n",
      "Epoch 12/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 326ms/step - accuracy: 0.8470 - loss: 0.3929 - val_accuracy: 0.7672 - val_loss: 0.5257\n",
      "Epoch 13/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.8476 - loss: 0.3944 - val_accuracy: 0.7833 - val_loss: 0.5084\n",
      "Epoch 14/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 326ms/step - accuracy: 0.8603 - loss: 0.3666 - val_accuracy: 0.7914 - val_loss: 0.5100\n",
      "Epoch 15/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 329ms/step - accuracy: 0.8636 - loss: 0.3428 - val_accuracy: 0.7712 - val_loss: 0.5255\n",
      "Epoch 16/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.8860 - loss: 0.3070 - val_accuracy: 0.8022 - val_loss: 0.5236\n",
      "Epoch 17/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.9002 - loss: 0.2690 - val_accuracy: 0.7914 - val_loss: 0.5715\n",
      "Epoch 18/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.9049 - loss: 0.2484 - val_accuracy: 0.7806 - val_loss: 0.5959\n",
      "Epoch 19/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.9110 - loss: 0.2365 - val_accuracy: 0.7779 - val_loss: 0.6250\n",
      "Epoch 20/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.9265 - loss: 0.1916 - val_accuracy: 0.7739 - val_loss: 0.6888\n",
      "Epoch 21/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.9340 - loss: 0.1634 - val_accuracy: 0.7591 - val_loss: 0.8417\n",
      "ğŸ Best epoch for Fold 9: 11\n",
      "âœ… Fold 9 test accuracy: 0.8228\n",
      "\n",
      "ğŸ§ª Fold 10 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 327ms/step - accuracy: 0.5713 - loss: 0.8233 - val_accuracy: 0.5922 - val_loss: 0.6765\n",
      "Epoch 2/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.6145 - loss: 0.6747 - val_accuracy: 0.5922 - val_loss: 0.6765\n",
      "Epoch 3/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6145 - loss: 0.6755 - val_accuracy: 0.5922 - val_loss: 0.6775\n",
      "Epoch 4/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 324ms/step - accuracy: 0.6025 - loss: 0.6784 - val_accuracy: 0.5922 - val_loss: 0.6893\n",
      "Epoch 5/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6145 - loss: 0.6871 - val_accuracy: 0.5922 - val_loss: 0.6855\n",
      "Epoch 6/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6145 - loss: 0.6825 - val_accuracy: 0.5922 - val_loss: 0.6827\n",
      "Epoch 7/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 327ms/step - accuracy: 0.6145 - loss: 0.6790 - val_accuracy: 0.5922 - val_loss: 0.6807\n",
      "Epoch 8/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 326ms/step - accuracy: 0.6145 - loss: 0.6763 - val_accuracy: 0.5922 - val_loss: 0.6793\n",
      "Epoch 9/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6145 - loss: 0.6742 - val_accuracy: 0.5922 - val_loss: 0.6782\n",
      "Epoch 10/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 325ms/step - accuracy: 0.6145 - loss: 0.6726 - val_accuracy: 0.5922 - val_loss: 0.6775\n",
      "Epoch 11/100\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 323ms/step - accuracy: 0.6145 - loss: 0.6714 - val_accuracy: 0.5922 - val_loss: 0.6769\n",
      "ğŸ Best epoch for Fold 10: 1\n",
      "âœ… Fold 10 test accuracy: 0.6019\n",
      "\n",
      "ğŸ“Œ Mean optimal epoch across folds: 7\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 3: K-Fold Cross-Validation\n",
    "\n",
    "# Early stopping callback\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    # min_delta=1e-4,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "k = 10  # Number of folds\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "all_test_accuracies = []\n",
    "best_epochs = []\n",
    "\n",
    "# Model creation function\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(224, 224, 3)),\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(paths, labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def load_img(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = img / 255.0\n",
    "\n",
    "        # 1) Boost blue channel\n",
    "        img = tf.clip_by_value(img + [0.0, 0.0, 0.2], 0.0, 1.0)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    return ds.map(load_img).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for trainval_index, test_index in skf.split(filepaths, labels):\n",
    "    print(f\"\\nğŸ§ª Fold {fold} -----------------------------\")\n",
    "\n",
    "    # Split into trainval and test\n",
    "    X_trainval, X_test = filepaths[trainval_index], filepaths[test_index]\n",
    "    y_trainval, y_test = labels[trainval_index], labels[test_index]\n",
    "\n",
    "    # Further split trainval into train and val (e.g. 80/20)\n",
    "    val_split = int(0.8 * len(X_trainval))\n",
    "    X_train, X_val = X_trainval[:val_split], X_trainval[val_split:]\n",
    "    y_train, y_val = y_trainval[:val_split], y_trainval[val_split:]\n",
    "\n",
    "\n",
    "    # Preprocess each split\n",
    "    train_ds = preprocess(X_train, y_train)\n",
    "    val_ds = preprocess(X_val, y_val)\n",
    "    test_ds = preprocess(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # Train model with early stopping\n",
    "    model = create_model()\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,\n",
    "        callbacks=[earlystop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Record best epoch (smallest val_loss)\n",
    "    best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "    best_epochs.append(best_epoch)\n",
    "    print(f\"ğŸ Best epoch for Fold {fold}: {best_epoch}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
    "    all_test_accuracies.append(test_acc)\n",
    "    print(f\"âœ… Fold {fold} test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Calculate mean best epoch\n",
    "ep_mean = int(np.round(np.mean(best_epochs)))\n",
    "print(f\"\\nğŸ“Œ Mean optimal epoch across folds: {ep_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1440c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 376ms/step - accuracy: 0.5888 - loss: 0.7158\n",
      "Epoch 2/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 351ms/step - accuracy: 0.5957 - loss: 0.6754\n",
      "Epoch 3/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 350ms/step - accuracy: 0.6123 - loss: 0.6625\n",
      "Epoch 4/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 350ms/step - accuracy: 0.7521 - loss: 0.5417\n",
      "Epoch 5/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 354ms/step - accuracy: 0.8084 - loss: 0.4564\n",
      "Epoch 6/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 358ms/step - accuracy: 0.8379 - loss: 0.3868\n",
      "Epoch 7/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 353ms/step - accuracy: 0.8499 - loss: 0.3443\n",
      "Epoch 8/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 349ms/step - accuracy: 0.8651 - loss: 0.3153\n",
      "Epoch 9/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 354ms/step - accuracy: 0.8720 - loss: 0.3055\n",
      "Epoch 10/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 350ms/step - accuracy: 0.8767 - loss: 0.2906\n",
      "Epoch 11/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 350ms/step - accuracy: 0.8673 - loss: 0.3084\n",
      "Epoch 12/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 351ms/step - accuracy: 0.8773 - loss: 0.2901\n",
      "Epoch 13/13\n",
      "\u001b[1m104/104\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 351ms/step - accuracy: 0.8977 - loss: 0.2612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21813400140>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell Block 4: Final Model Training on data again, but for ep_mean Epochs (no validation needed)\n",
    "\n",
    "## NOTE: THIS IS NOT TESTING ON HIDDEN DATA - IT WAS TECHNICALLY SEEN IN THE k-FOLD.\n",
    "## CAN TALK ABOUT THIS TO AYUSHMAN\n",
    "\n",
    "# Split all data into 80% train and 20% test\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    filepaths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Use your same preprocess function\n",
    "train_final_ds = preprocess(X_train_final, y_train_final)\n",
    "test_final_ds = preprocess(X_test_final, y_test_final)\n",
    "\n",
    "# Create and train model with ep_mean\n",
    "final_model = create_model()\n",
    "final_model.fit(\n",
    "    train_final_ds,\n",
    "    epochs=ep_mean,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "266fba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š 10-Fold Test Accuracy: 0.6487 Â± 0.0823\n",
      "ğŸ Final model test accuracy (trained on 80% for 13 epochs): 0.8194\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 5: Final Evaluation\n",
    "\n",
    "# Evaluate final model on the 20% test set\n",
    "final_test_loss, final_test_acc = final_model.evaluate(test_final_ds, verbose=0)\n",
    "\n",
    "# Report both results\n",
    "print(f\"\\nğŸ“Š {k}-Fold Test Accuracy: {np.mean(all_test_accuracies):.4f} Â± {np.std(all_test_accuracies):.4f}\")\n",
    "print(f\"ğŸ Final model test accuracy (trained on 80% for {ep_mean} epochs): {final_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43359819",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_final_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. Extract true labels and model scores from your hold-out dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m y_true = np.concatenate([y.numpy() \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_final_ds\u001b[49m], axis=\u001b[32m0\u001b[39m)\n\u001b[32m      7\u001b[39m y_pred_prob = final_model.predict(test_final_ds)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. If your model outputs two probabilities (one per class), take the â€œpositiveâ€ class\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'test_final_ds' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, roc_curve, auc, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Extract true labels and model scores from your hold-out dataset\n",
    "y_true = np.concatenate([y.numpy() for x, y in test_final_ds], axis=0)\n",
    "y_pred_prob = final_model.predict(test_final_ds)\n",
    "\n",
    "# 2. If your model outputs two probabilities (one per class), take the â€œpositiveâ€ class\n",
    "if y_pred_prob.ndim > 1 and y_pred_prob.shape[1] > 1:\n",
    "    y_scores = y_pred_prob[:, 1]\n",
    "else:\n",
    "    y_scores = y_pred_prob.ravel()\n",
    "\n",
    "# 3. Compute ROC curve metrics\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 4. Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)               # ROC curve\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')  # chance line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Receiver Operating Characteristic (AUC = {roc_auc:.2f})')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# 1. Turn your predicted probabilities into binary preds (threshold = 0.5)\n",
    "y_pred = (y_scores >= 0.5).astype(int)\n",
    "\n",
    "# 2. Compute precision, recall, F1\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall    = recall_score(y_true, y_pred)\n",
    "f1        = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1 Score:  {f1:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
