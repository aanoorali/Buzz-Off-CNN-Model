{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae6385",
   "metadata": {},
   "source": [
    "Varroa Mite Detection 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9629b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 1: Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f75b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 2: Load Data and Preprocess\n",
    "\n",
    "df = pd.read_csv('labels.csv')\n",
    "\n",
    "df['filename'] = df['filename'].apply(lambda fn: os.path.join('images', fn.strip()))\n",
    "\n",
    "filepaths = df['filename'].values\n",
    "labels = df['has_mite'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b27035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Fold 1 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 438ms/step - accuracy: 0.5788 - loss: 1.0416 - val_accuracy: 0.5839 - val_loss: 0.6897\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 421ms/step - accuracy: 0.6290 - loss: 0.6774 - val_accuracy: 0.5839 - val_loss: 0.6818\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 444ms/step - accuracy: 0.6290 - loss: 0.6804 - val_accuracy: 0.5839 - val_loss: 0.6798\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6306 - loss: 0.6723 - val_accuracy: 0.5839 - val_loss: 0.6800\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.6290 - loss: 0.6643 - val_accuracy: 0.5839 - val_loss: 0.6816\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6290 - loss: 0.6694 - val_accuracy: 0.5839 - val_loss: 0.6803\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6176 - loss: 0.6707\n",
      "✅ Fold 1 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 2 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 392ms/step - accuracy: 0.5836 - loss: 1.5282 - val_accuracy: 0.6040 - val_loss: 0.6822\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.6215 - loss: 0.6813 - val_accuracy: 0.6040 - val_loss: 0.6722\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 461ms/step - accuracy: 0.6215 - loss: 0.6712 - val_accuracy: 0.6040 - val_loss: 0.6725\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 486ms/step - accuracy: 0.6215 - loss: 0.6696 - val_accuracy: 0.6040 - val_loss: 0.6715\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.6215 - loss: 0.6669 - val_accuracy: 0.6040 - val_loss: 0.6709\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6215 - loss: 0.6667 - val_accuracy: 0.6040 - val_loss: 0.6699\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6215 - loss: 0.6646 - val_accuracy: 0.6040 - val_loss: 0.6686\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.6215 - loss: 0.6625 - val_accuracy: 0.6040 - val_loss: 0.6654\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6215 - loss: 0.6592 - val_accuracy: 0.6040 - val_loss: 0.6593\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6215 - loss: 0.6559 - val_accuracy: 0.6040 - val_loss: 0.6663\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6215 - loss: 0.6473 - val_accuracy: 0.6040 - val_loss: 0.6701\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.5962 - loss: 0.6352 - val_accuracy: 0.6040 - val_loss: 0.6913\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6332 - loss: 0.6394\n",
      "✅ Fold 2 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 3 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - accuracy: 0.5402 - loss: 0.9462 - val_accuracy: 0.5436 - val_loss: 0.6905\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.6331 - loss: 0.6722 - val_accuracy: 0.5436 - val_loss: 0.7097\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 367ms/step - accuracy: 0.6331 - loss: 0.6687 - val_accuracy: 0.5436 - val_loss: 0.6918\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.6331 - loss: 0.6652 - val_accuracy: 0.5436 - val_loss: 0.6915\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5825 - loss: 0.6806\n",
      "✅ Fold 3 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 4 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 392ms/step - accuracy: 0.6215 - loss: 0.9907 - val_accuracy: 0.5705 - val_loss: 0.6820\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 371ms/step - accuracy: 0.6320 - loss: 0.6958 - val_accuracy: 0.5705 - val_loss: 0.6829\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.6361 - loss: 0.6897 - val_accuracy: 0.5705 - val_loss: 0.6921\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 372ms/step - accuracy: 0.6361 - loss: 0.6776 - val_accuracy: 0.5705 - val_loss: 0.6869\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5981 - loss: 0.6731\n",
      "✅ Fold 4 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 5 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - accuracy: 0.5268 - loss: 0.7515 - val_accuracy: 0.5973 - val_loss: 0.6758\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.6247 - loss: 0.6812 - val_accuracy: 0.5973 - val_loss: 0.6752\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 371ms/step - accuracy: 0.6247 - loss: 0.6735 - val_accuracy: 0.5973 - val_loss: 0.6764\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6247 - loss: 0.6784 - val_accuracy: 0.5973 - val_loss: 0.6777\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.6247 - loss: 0.6694 - val_accuracy: 0.5973 - val_loss: 0.6753\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6059 - loss: 0.6726\n",
      "✅ Fold 5 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 6 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 383ms/step - accuracy: 0.5388 - loss: 0.9984 - val_accuracy: 0.5906 - val_loss: 0.6789\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 374ms/step - accuracy: 0.6271 - loss: 0.6758 - val_accuracy: 0.5906 - val_loss: 0.6733\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - accuracy: 0.6143 - loss: 0.6642 - val_accuracy: 0.5906 - val_loss: 0.6721\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 379ms/step - accuracy: 0.6005 - loss: 0.6584 - val_accuracy: 0.6644 - val_loss: 0.6408\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 371ms/step - accuracy: 0.6918 - loss: 0.6024 - val_accuracy: 0.6242 - val_loss: 0.6617\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.6729 - loss: 0.5908 - val_accuracy: 0.6577 - val_loss: 0.6567\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 388ms/step - accuracy: 0.7513 - loss: 0.5169 - val_accuracy: 0.6376 - val_loss: 0.6533\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7152 - loss: 0.6038\n",
      "✅ Fold 6 test accuracy: 0.7195\n",
      "\n",
      "🧪 Fold 7 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - accuracy: 0.6071 - loss: 1.0479 - val_accuracy: 0.5638 - val_loss: 0.7065\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.6385 - loss: 0.6667 - val_accuracy: 0.5638 - val_loss: 0.6874\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - accuracy: 0.6385 - loss: 0.6780 - val_accuracy: 0.5638 - val_loss: 0.6849\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - accuracy: 0.6385 - loss: 0.6780 - val_accuracy: 0.5638 - val_loss: 0.6955\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 374ms/step - accuracy: 0.6385 - loss: 0.6692 - val_accuracy: 0.5638 - val_loss: 0.6927\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - accuracy: 0.6385 - loss: 0.6754 - val_accuracy: 0.5638 - val_loss: 0.6850\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5839 - loss: 0.6807\n",
      "✅ Fold 7 test accuracy: 0.5976\n",
      "\n",
      "🧪 Fold 8 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 391ms/step - accuracy: 0.5968 - loss: 1.0718 - val_accuracy: 0.5772 - val_loss: 0.7061\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 372ms/step - accuracy: 0.6290 - loss: 0.6633 - val_accuracy: 0.5772 - val_loss: 0.6862\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.6290 - loss: 0.6821 - val_accuracy: 0.5772 - val_loss: 0.6819\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 378ms/step - accuracy: 0.6290 - loss: 0.6725 - val_accuracy: 0.5772 - val_loss: 0.6811\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.6290 - loss: 0.6689 - val_accuracy: 0.5772 - val_loss: 0.6822\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 381ms/step - accuracy: 0.6290 - loss: 0.6642 - val_accuracy: 0.5772 - val_loss: 0.6787\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.6290 - loss: 0.6612 - val_accuracy: 0.5772 - val_loss: 0.6785\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 379ms/step - accuracy: 0.6205 - loss: 0.6443 - val_accuracy: 0.5772 - val_loss: 0.6784\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - accuracy: 0.6290 - loss: 0.6585 - val_accuracy: 0.5772 - val_loss: 0.6912\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - accuracy: 0.6290 - loss: 0.6896 - val_accuracy: 0.5772 - val_loss: 0.6904\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6152 - loss: 0.6640\n",
      "✅ Fold 8 test accuracy: 0.5976\n",
      "\n",
      "🧪 Fold 9 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 385ms/step - accuracy: 0.5377 - loss: 1.0825 - val_accuracy: 0.5973 - val_loss: 0.6787\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.6228 - loss: 0.6856 - val_accuracy: 0.5973 - val_loss: 0.6740\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 381ms/step - accuracy: 0.6228 - loss: 0.6858 - val_accuracy: 0.5973 - val_loss: 0.6806\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 372ms/step - accuracy: 0.6228 - loss: 0.6850 - val_accuracy: 0.5973 - val_loss: 0.6727\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.6228 - loss: 0.6608 - val_accuracy: 0.5973 - val_loss: 0.6676\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6228 - loss: 0.5942 - val_accuracy: 0.5973 - val_loss: 0.8171\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - accuracy: 0.6228 - loss: 0.5692 - val_accuracy: 0.5973 - val_loss: 0.6748\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.6228 - loss: 0.5897 - val_accuracy: 0.5973 - val_loss: 0.7120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6486 - loss: 0.5801\n",
      "✅ Fold 9 test accuracy: 0.6098\n",
      "\n",
      "🧪 Fold 10 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - accuracy: 0.5416 - loss: 1.0730 - val_accuracy: 0.5772 - val_loss: 0.6888\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - accuracy: 0.6344 - loss: 0.6870 - val_accuracy: 0.5772 - val_loss: 0.6878\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.6344 - loss: 0.6746 - val_accuracy: 0.5772 - val_loss: 0.6861\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6344 - loss: 0.6844 - val_accuracy: 0.5772 - val_loss: 0.6813\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.6344 - loss: 0.6689 - val_accuracy: 0.5772 - val_loss: 0.6768\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6344 - loss: 0.6547 - val_accuracy: 0.5772 - val_loss: 0.6750\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6344 - loss: 0.6386 - val_accuracy: 0.5772 - val_loss: 0.6695\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.7000 - loss: 0.5946 - val_accuracy: 0.6443 - val_loss: 0.7321\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.7824 - loss: 0.4835 - val_accuracy: 0.7114 - val_loss: 0.6279\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.8093 - loss: 0.4397 - val_accuracy: 0.6309 - val_loss: 0.7329\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 360ms/step - accuracy: 0.7776 - loss: 0.4367 - val_accuracy: 0.6107 - val_loss: 0.7523\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 367ms/step - accuracy: 0.7621 - loss: 0.4370 - val_accuracy: 0.7315 - val_loss: 0.7008\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7352 - loss: 0.5534\n",
      "✅ Fold 10 test accuracy: 0.7439\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 3: K-Fold Cross-Validation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# define it once (you can tweak patience, monitor, etc. as you like)\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',        # watch validation loss\n",
    "    patience=3,               # decreased patience from 5 to 3\n",
    "    min_delta=1e-4,            # add a minimum delta to reduce sensitivity to small changes and floating point error\n",
    "    restore_best_weights=True  # roll back to the best weights seen\n",
    ")\n",
    "\n",
    "\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "all_test_accuracies = []\n",
    "\n",
    "for trainval_index, test_index in skf.split(filepaths, labels):\n",
    "    print(f\"\\n🧪 Fold {fold} -----------------------------\")\n",
    "\n",
    "    # Split into trainval and test\n",
    "    X_trainval, X_test = filepaths[trainval_index], filepaths[test_index]\n",
    "    y_trainval, y_test = labels[trainval_index], labels[test_index]\n",
    "\n",
    "    # Further split trainval into train and val (e.g. 80/20)\n",
    "    val_split = int(0.8 * len(X_trainval))\n",
    "    X_train, X_val = X_trainval[:val_split], X_trainval[val_split:]\n",
    "    y_train, y_val = y_trainval[:val_split], y_trainval[val_split:]\n",
    "\n",
    "\n",
    "    def preprocess(paths, labels):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "        def load_img(path, label):\n",
    "            img = tf.io.read_file(path)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, [224, 224])\n",
    "            img = img / 255.0\n",
    "            return img, label\n",
    "\n",
    "        return ds.map(load_img).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = preprocess(X_train, y_train)\n",
    "    val_ds = preprocess(X_val, y_val)\n",
    "    test_ds = preprocess(X_test, y_test)\n",
    "\n",
    "\n",
    "    # Build a fresh model for each fold\n",
    "    def create_model():\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=(224, 224, 3)),\n",
    "            layers.Conv2D(32, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "    # # Train\n",
    "    # model.fit(train_ds, validation_data=val_ds, epochs=100, verbose=1)\n",
    "\n",
    "    # Train with early stopping\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,            # generous upper bound\n",
    "        callbacks=[earlystop], # ← here!\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    all_test_accuracies.append(test_acc)\n",
    "    print(f\"✅ Fold {fold} test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266fba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 10-Fold Test Accuracy: 0.6280 ± 0.0522\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 4: Final Evaluation\n",
    "mean_acc = np.mean(all_test_accuracies)\n",
    "std_acc = np.std(all_test_accuracies)\n",
    "print(f\"\\n📊 {k}-Fold Test Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc151d05",
   "metadata": {},
   "source": [
    "Add Precision, Make a Confusion Matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
