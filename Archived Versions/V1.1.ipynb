{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae6385",
   "metadata": {},
   "source": [
    "Varroa Mite Detection 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9629b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 1: Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f75b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 2: Load Data and Preprocess\n",
    "\n",
    "df = pd.read_csv('labels.csv')\n",
    "\n",
    "df['filename'] = df['filename'].apply(lambda fn: os.path.join('images', fn.strip()))\n",
    "\n",
    "filepaths = df['filename'].values\n",
    "labels = df['has_mite'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b27035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Fold 1 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 424ms/step - accuracy: 0.5144 - loss: 0.7602 - val_accuracy: 0.5839 - val_loss: 0.6812\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6290 - loss: 0.6763 - val_accuracy: 0.5839 - val_loss: 0.6804\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6290 - loss: 0.6734 - val_accuracy: 0.5839 - val_loss: 0.6808\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6290 - loss: 0.6727 - val_accuracy: 0.5839 - val_loss: 0.6768\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 414ms/step - accuracy: 0.6290 - loss: 0.6698 - val_accuracy: 0.5839 - val_loss: 0.6917\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6290 - loss: 0.6907 - val_accuracy: 0.5839 - val_loss: 0.6907\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 418ms/step - accuracy: 0.6290 - loss: 0.6891 - val_accuracy: 0.5839 - val_loss: 0.6897\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6290 - loss: 0.6875 - val_accuracy: 0.5839 - val_loss: 0.6888\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.6290 - loss: 0.6859 - val_accuracy: 0.5839 - val_loss: 0.6879\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6176 - loss: 0.6618\n",
      "✅ Fold 1 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 2 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.5604 - loss: 1.2014 - val_accuracy: 0.6040 - val_loss: 0.6722\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.6215 - loss: 0.6817 - val_accuracy: 0.6040 - val_loss: 0.6768\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.6215 - loss: 0.6831 - val_accuracy: 0.6040 - val_loss: 0.6724\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6215 - loss: 0.6767 - val_accuracy: 0.6040 - val_loss: 0.6723\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6215 - loss: 0.6713 - val_accuracy: 0.6040 - val_loss: 0.6695\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6215 - loss: 0.6678 - val_accuracy: 0.6040 - val_loss: 0.6679\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6215 - loss: 0.6726 - val_accuracy: 0.6040 - val_loss: 0.6717\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6215 - loss: 0.6662 - val_accuracy: 0.6040 - val_loss: 0.6664\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6286 - loss: 0.6438 - val_accuracy: 0.5973 - val_loss: 0.6554\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6237 - loss: 0.6541 - val_accuracy: 0.6040 - val_loss: 0.6640\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6024 - loss: 0.6564 - val_accuracy: 0.6242 - val_loss: 0.6524\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.6668 - loss: 0.6400 - val_accuracy: 0.6376 - val_loss: 0.6545\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.7004 - loss: 0.6253 - val_accuracy: 0.6040 - val_loss: 0.6666\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.7316 - loss: 0.5399 - val_accuracy: 0.6510 - val_loss: 0.6849\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.7884 - loss: 0.4688 - val_accuracy: 0.6711 - val_loss: 0.7227\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.8070 - loss: 0.4086 - val_accuracy: 0.5973 - val_loss: 0.7430\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6414 - loss: 0.6265\n",
      "✅ Fold 2 test accuracy: 0.6265\n",
      "\n",
      "🧪 Fold 3 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.5335 - loss: 1.1622 - val_accuracy: 0.5436 - val_loss: 0.6952\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6331 - loss: 0.6767 - val_accuracy: 0.5436 - val_loss: 0.7159\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6331 - loss: 0.6707 - val_accuracy: 0.5436 - val_loss: 0.6890\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6331 - loss: 0.6705 - val_accuracy: 0.5436 - val_loss: 0.6992\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6331 - loss: 0.6578 - val_accuracy: 0.5436 - val_loss: 0.6981\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.6331 - loss: 0.6593 - val_accuracy: 0.5436 - val_loss: 0.6967\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.6331 - loss: 0.6576 - val_accuracy: 0.5436 - val_loss: 0.6928\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 420ms/step - accuracy: 0.6331 - loss: 0.6515 - val_accuracy: 0.5436 - val_loss: 0.6993\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5825 - loss: 0.6826\n",
      "✅ Fold 3 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 4 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 433ms/step - accuracy: 0.6327 - loss: 0.9767 - val_accuracy: 0.5705 - val_loss: 0.6835\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6361 - loss: 0.6840 - val_accuracy: 0.5705 - val_loss: 0.6838\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6361 - loss: 0.6856 - val_accuracy: 0.5705 - val_loss: 0.6857\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6361 - loss: 0.6783 - val_accuracy: 0.5705 - val_loss: 0.6841\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 420ms/step - accuracy: 0.6361 - loss: 0.6755 - val_accuracy: 0.5705 - val_loss: 0.6829\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.6361 - loss: 0.6731 - val_accuracy: 0.5705 - val_loss: 0.6820\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6361 - loss: 0.6673 - val_accuracy: 0.5705 - val_loss: 0.6825\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 448ms/step - accuracy: 0.6515 - loss: 0.6683 - val_accuracy: 0.5705 - val_loss: 0.6832\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6384 - loss: 0.6672 - val_accuracy: 0.5705 - val_loss: 0.6823\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6273 - loss: 0.6631 - val_accuracy: 0.5705 - val_loss: 0.6783\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.6607 - loss: 0.6451 - val_accuracy: 0.5705 - val_loss: 0.6666\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.6320 - loss: 0.6301 - val_accuracy: 0.5973 - val_loss: 0.6492\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6781 - loss: 0.5959 - val_accuracy: 0.6913 - val_loss: 0.6148\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.7179 - loss: 0.5643 - val_accuracy: 0.6040 - val_loss: 0.6310\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.7226 - loss: 0.5676 - val_accuracy: 0.6779 - val_loss: 0.6268\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.7520 - loss: 0.5285 - val_accuracy: 0.6711 - val_loss: 0.6188\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 421ms/step - accuracy: 0.8026 - loss: 0.4527 - val_accuracy: 0.6174 - val_loss: 0.6237\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.7755 - loss: 0.4609 - val_accuracy: 0.6846 - val_loss: 0.6352\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6811 - loss: 0.6059\n",
      "✅ Fold 4 test accuracy: 0.6747\n",
      "\n",
      "🧪 Fold 5 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.5661 - loss: 0.9908 - val_accuracy: 0.5973 - val_loss: 0.6761\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6247 - loss: 0.6756 - val_accuracy: 0.5973 - val_loss: 0.6740\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6247 - loss: 0.6752 - val_accuracy: 0.5973 - val_loss: 0.6715\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6247 - loss: 0.6751 - val_accuracy: 0.5973 - val_loss: 0.6703\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6247 - loss: 0.6727 - val_accuracy: 0.5973 - val_loss: 0.6753\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6247 - loss: 0.6648 - val_accuracy: 0.5973 - val_loss: 0.6439\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6247 - loss: 0.6428 - val_accuracy: 0.5973 - val_loss: 0.6504\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6247 - loss: 0.6118 - val_accuracy: 0.5973 - val_loss: 0.6572\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.6247 - loss: 0.5678 - val_accuracy: 0.5973 - val_loss: 0.6381\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6247 - loss: 0.5354 - val_accuracy: 0.5973 - val_loss: 0.6411\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.7454 - loss: 0.4862 - val_accuracy: 0.6577 - val_loss: 0.6476\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.7616 - loss: 0.4673 - val_accuracy: 0.7383 - val_loss: 0.6847\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.8362 - loss: 0.4210 - val_accuracy: 0.7114 - val_loss: 0.6973\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 391ms/step - accuracy: 0.8520 - loss: 0.3999 - val_accuracy: 0.7114 - val_loss: 0.7939\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6059 - loss: 0.5533\n",
      "✅ Fold 5 test accuracy: 0.6024\n",
      "\n",
      "🧪 Fold 6 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 422ms/step - accuracy: 0.5024 - loss: 0.7376 - val_accuracy: 0.5906 - val_loss: 0.6758\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 418ms/step - accuracy: 0.6271 - loss: 0.6746 - val_accuracy: 0.5906 - val_loss: 0.6774\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6271 - loss: 0.6732 - val_accuracy: 0.5906 - val_loss: 0.6755\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6271 - loss: 0.6673 - val_accuracy: 0.5906 - val_loss: 0.6751\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6271 - loss: 0.6680 - val_accuracy: 0.5906 - val_loss: 0.6783\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6271 - loss: 0.6671 - val_accuracy: 0.5906 - val_loss: 0.6747\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.6271 - loss: 0.6626 - val_accuracy: 0.5906 - val_loss: 0.6677\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6271 - loss: 0.6430 - val_accuracy: 0.5906 - val_loss: 0.6653\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6271 - loss: 0.6146 - val_accuracy: 0.5906 - val_loss: 0.7274\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 459ms/step - accuracy: 0.6271 - loss: 0.5748 - val_accuracy: 0.5906 - val_loss: 0.7458\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 458ms/step - accuracy: 0.6336 - loss: 0.5352 - val_accuracy: 0.6174 - val_loss: 0.7214\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.7242 - loss: 0.4837 - val_accuracy: 0.7047 - val_loss: 0.6815\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.7783 - loss: 0.4504 - val_accuracy: 0.6980 - val_loss: 0.6711\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5917 - loss: 0.6393\n",
      "✅ Fold 6 test accuracy: 0.5976\n",
      "\n",
      "🧪 Fold 7 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 416ms/step - accuracy: 0.5150 - loss: 1.0001 - val_accuracy: 0.5638 - val_loss: 0.6850\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6385 - loss: 0.6744 - val_accuracy: 0.5638 - val_loss: 0.6849\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6385 - loss: 0.6722 - val_accuracy: 0.5638 - val_loss: 0.6855\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.6385 - loss: 0.6668 - val_accuracy: 0.5638 - val_loss: 0.6829\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.6385 - loss: 0.6639 - val_accuracy: 0.5638 - val_loss: 0.6817\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 435ms/step - accuracy: 0.6385 - loss: 0.6598 - val_accuracy: 0.5638 - val_loss: 0.6814\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6385 - loss: 0.6563 - val_accuracy: 0.5638 - val_loss: 0.6768\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6385 - loss: 0.6471 - val_accuracy: 0.5638 - val_loss: 0.6811\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6385 - loss: 0.6197 - val_accuracy: 0.5638 - val_loss: 0.6850\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 418ms/step - accuracy: 0.6385 - loss: 0.5863 - val_accuracy: 0.5638 - val_loss: 0.7303\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 441ms/step - accuracy: 0.6493 - loss: 0.5514 - val_accuracy: 0.6376 - val_loss: 0.8518\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.7670 - loss: 0.4879 - val_accuracy: 0.6376 - val_loss: 0.8808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5839 - loss: 0.6739\n",
      "✅ Fold 7 test accuracy: 0.5976\n",
      "\n",
      "🧪 Fold 8 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - accuracy: 0.5477 - loss: 1.2795 - val_accuracy: 0.5772 - val_loss: 0.6816\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6290 - loss: 0.6797 - val_accuracy: 0.5772 - val_loss: 0.6831\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6290 - loss: 0.6785 - val_accuracy: 0.5772 - val_loss: 0.6813\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6290 - loss: 0.6736 - val_accuracy: 0.5772 - val_loss: 0.6812\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.6290 - loss: 0.6728 - val_accuracy: 0.5772 - val_loss: 0.6904\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 359ms/step - accuracy: 0.6290 - loss: 0.6714 - val_accuracy: 0.5772 - val_loss: 0.6950\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.6290 - loss: 0.6731 - val_accuracy: 0.5772 - val_loss: 0.7105\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 414ms/step - accuracy: 0.6290 - loss: 0.6726 - val_accuracy: 0.5772 - val_loss: 0.6921\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.6290 - loss: 0.6777 - val_accuracy: 0.5772 - val_loss: 0.6807\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6290 - loss: 0.6767 - val_accuracy: 0.5772 - val_loss: 0.6750\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.6290 - loss: 0.6608 - val_accuracy: 0.5772 - val_loss: 0.6676\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.5990 - loss: 0.6564 - val_accuracy: 0.5772 - val_loss: 0.6913\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.6290 - loss: 0.6897 - val_accuracy: 0.5772 - val_loss: 0.6905\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6290 - loss: 0.6882 - val_accuracy: 0.5772 - val_loss: 0.6896\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6290 - loss: 0.6867 - val_accuracy: 0.5772 - val_loss: 0.6887\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6290 - loss: 0.6852 - val_accuracy: 0.5772 - val_loss: 0.6880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6152 - loss: 0.6433\n",
      "✅ Fold 8 test accuracy: 0.5976\n",
      "\n",
      "🧪 Fold 9 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.5860 - loss: 1.1243 - val_accuracy: 0.5973 - val_loss: 0.6725\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.6228 - loss: 0.6858 - val_accuracy: 0.5973 - val_loss: 0.6923\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6228 - loss: 0.6896 - val_accuracy: 0.5973 - val_loss: 0.6779\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 433ms/step - accuracy: 0.6228 - loss: 0.6763 - val_accuracy: 0.5973 - val_loss: 0.6889\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.6228 - loss: 0.6853 - val_accuracy: 0.5973 - val_loss: 0.6734\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6228 - loss: 0.6797 - val_accuracy: 0.5973 - val_loss: 0.6810\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6486 - loss: 0.6532\n",
      "✅ Fold 9 test accuracy: 0.6098\n",
      "\n",
      "🧪 Fold 10 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.6038 - loss: 1.1344 - val_accuracy: 0.5772 - val_loss: 0.6885\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 374ms/step - accuracy: 0.6344 - loss: 0.6951 - val_accuracy: 0.5772 - val_loss: 0.6925\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6344 - loss: 0.6652 - val_accuracy: 0.5772 - val_loss: 0.6883\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6344 - loss: 0.6849 - val_accuracy: 0.5772 - val_loss: 0.6827\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.6344 - loss: 0.6688 - val_accuracy: 0.5772 - val_loss: 0.7006\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 437ms/step - accuracy: 0.6344 - loss: 0.6658 - val_accuracy: 0.5772 - val_loss: 0.6923\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.6344 - loss: 0.6766 - val_accuracy: 0.5772 - val_loss: 0.6820\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.6344 - loss: 0.6769 - val_accuracy: 0.5772 - val_loss: 0.6809\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6344 - loss: 0.6703 - val_accuracy: 0.5772 - val_loss: 0.6795\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6344 - loss: 0.6803 - val_accuracy: 0.5772 - val_loss: 0.6886\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.6320 - loss: 0.6599 - val_accuracy: 0.5772 - val_loss: 0.6843\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6580 - loss: 0.6673 - val_accuracy: 0.5839 - val_loss: 0.6783\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.6354 - loss: 0.6615 - val_accuracy: 0.5839 - val_loss: 0.6495\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6382 - loss: 0.6244 - val_accuracy: 0.6376 - val_loss: 0.6593\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.6940 - loss: 0.6234 - val_accuracy: 0.6443 - val_loss: 0.6298\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.7362 - loss: 0.5412 - val_accuracy: 0.6174 - val_loss: 0.6609\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.7196 - loss: 0.5262 - val_accuracy: 0.6510 - val_loss: 0.6467\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.7570 - loss: 0.4796 - val_accuracy: 0.6510 - val_loss: 0.6485\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.7911 - loss: 0.4371 - val_accuracy: 0.6309 - val_loss: 0.6639\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 414ms/step - accuracy: 0.8223 - loss: 0.3856 - val_accuracy: 0.6711 - val_loss: 0.8091\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6652 - loss: 0.6397\n",
      "✅ Fold 10 test accuracy: 0.6585\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 3: K-Fold Cross-Validation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# define it once (you can tweak patience, monitor, etc. as you like)\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',        # watch validation loss\n",
    "    patience=5,               # stop if no improvement for 10 epochs\n",
    "    restore_best_weights=True  # roll back to the best weights seen\n",
    ")\n",
    "\n",
    "\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "all_test_accuracies = []\n",
    "\n",
    "for trainval_index, test_index in skf.split(filepaths, labels):\n",
    "    print(f\"\\n🧪 Fold {fold} -----------------------------\")\n",
    "\n",
    "    # Split into trainval and test\n",
    "    X_trainval, X_test = filepaths[trainval_index], filepaths[test_index]\n",
    "    y_trainval, y_test = labels[trainval_index], labels[test_index]\n",
    "\n",
    "    # Further split trainval into train and val (e.g. 80/20)\n",
    "    val_split = int(0.8 * len(X_trainval))\n",
    "    X_train, X_val = X_trainval[:val_split], X_trainval[val_split:]\n",
    "    y_train, y_val = y_trainval[:val_split], y_trainval[val_split:]\n",
    "\n",
    "\n",
    "    def preprocess(paths, labels):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "        def load_img(path, label):\n",
    "            img = tf.io.read_file(path)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, [224, 224])\n",
    "            img = img / 255.0\n",
    "            return img, label\n",
    "\n",
    "        return ds.map(load_img).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = preprocess(X_train, y_train)\n",
    "    val_ds = preprocess(X_val, y_val)\n",
    "    test_ds = preprocess(X_test, y_test)\n",
    "\n",
    "\n",
    "    # Build a fresh model for each fold\n",
    "    def create_model():\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=(224, 224, 3)),\n",
    "            layers.Conv2D(32, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "    # # Train\n",
    "    # model.fit(train_ds, validation_data=val_ds, epochs=100, verbose=1)\n",
    "\n",
    "    # Train with early stopping\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,            # generous upper bound\n",
    "        callbacks=[earlystop], # ← here!\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    all_test_accuracies.append(test_acc)\n",
    "    print(f\"✅ Fold {fold} test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "266fba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 10-Fold Test Accuracy: 0.6169 ± 0.0264\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 4: Final Evaluation\n",
    "mean_acc = np.mean(all_test_accuracies)\n",
    "std_acc = np.std(all_test_accuracies)\n",
    "print(f\"\\n📊 {k}-Fold Test Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
