{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae6385",
   "metadata": {},
   "source": [
    "Varroa Mite Detection V1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9629b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 1: Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f75b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Block 2: Load Data and Preprocess\n",
    "\n",
    "df = pd.read_csv('labels.csv')\n",
    "\n",
    "df['filename'] = df['filename'].apply(lambda fn: os.path.join('images', fn.strip()))\n",
    "\n",
    "filepaths = df['filename'].values\n",
    "labels = df['has_mite'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b27035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Fold 1 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.4465 - loss: 0.8111 - val_accuracy: 0.5705 - val_loss: 0.6902\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 421ms/step - accuracy: 0.6297 - loss: 0.6736 - val_accuracy: 0.5705 - val_loss: 0.6899\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 370ms/step - accuracy: 0.6297 - loss: 0.6772 - val_accuracy: 0.5705 - val_loss: 0.6902\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.6297 - loss: 0.6772 - val_accuracy: 0.5705 - val_loss: 0.6841\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6297 - loss: 0.6717 - val_accuracy: 0.5705 - val_loss: 0.6886\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 389ms/step - accuracy: 0.6297 - loss: 0.6714 - val_accuracy: 0.5705 - val_loss: 0.6815\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 429ms/step - accuracy: 0.6297 - loss: 0.6691 - val_accuracy: 0.5705 - val_loss: 0.6890\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.6297 - loss: 0.6588 - val_accuracy: 0.5705 - val_loss: 0.6821\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6321 - loss: 0.6566 - val_accuracy: 0.5705 - val_loss: 0.6807\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 447ms/step - accuracy: 0.6329 - loss: 0.6441 - val_accuracy: 0.5772 - val_loss: 0.6840\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6105 - loss: 0.6391 - val_accuracy: 0.5705 - val_loss: 0.7028\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 372ms/step - accuracy: 0.6278 - loss: 0.6207 - val_accuracy: 0.5705 - val_loss: 0.6763\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - accuracy: 0.6520 - loss: 0.6143 - val_accuracy: 0.5772 - val_loss: 0.6836\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 356ms/step - accuracy: 0.6993 - loss: 0.5629 - val_accuracy: 0.6242 - val_loss: 0.6735\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.7564 - loss: 0.4901 - val_accuracy: 0.6644 - val_loss: 0.7137\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.7983 - loss: 0.4103 - val_accuracy: 0.6040 - val_loss: 0.7463\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.8429 - loss: 0.3534 - val_accuracy: 0.6510 - val_loss: 0.8244\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.8656 - loss: 0.3171 - val_accuracy: 0.6443 - val_loss: 0.8293\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 447ms/step - accuracy: 0.9128 - loss: 0.2312 - val_accuracy: 0.6242 - val_loss: 1.1961\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6399 - loss: 0.6415\n",
      "✅ Fold 1 test accuracy: 0.6627\n",
      "\n",
      "🧪 Fold 2 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 440ms/step - accuracy: 0.4902 - loss: 1.1588 - val_accuracy: 0.5839 - val_loss: 0.6815\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.6370 - loss: 0.6738 - val_accuracy: 0.5839 - val_loss: 0.6829\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6370 - loss: 0.6752 - val_accuracy: 0.5839 - val_loss: 0.6813\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6370 - loss: 0.6635 - val_accuracy: 0.5839 - val_loss: 0.6784\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6370 - loss: 0.6637 - val_accuracy: 0.5839 - val_loss: 0.6790\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6370 - loss: 0.6609 - val_accuracy: 0.5839 - val_loss: 0.6777\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 418ms/step - accuracy: 0.6370 - loss: 0.6607 - val_accuracy: 0.5839 - val_loss: 0.6766\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.6370 - loss: 0.6569 - val_accuracy: 0.5839 - val_loss: 0.6687\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6370 - loss: 0.6458 - val_accuracy: 0.5839 - val_loss: 0.6519\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6281 - loss: 0.6194 - val_accuracy: 0.5839 - val_loss: 0.6812\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6373 - loss: 0.6065 - val_accuracy: 0.5973 - val_loss: 0.6707\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.6318 - loss: 0.5906 - val_accuracy: 0.6577 - val_loss: 0.6692\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.7138 - loss: 0.5502 - val_accuracy: 0.6980 - val_loss: 0.6489\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 457ms/step - accuracy: 0.7585 - loss: 0.5122 - val_accuracy: 0.7181 - val_loss: 0.6478\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 451ms/step - accuracy: 0.7878 - loss: 0.4589 - val_accuracy: 0.6980 - val_loss: 0.6104\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 425ms/step - accuracy: 0.8158 - loss: 0.4380 - val_accuracy: 0.6779 - val_loss: 0.6499\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.8310 - loss: 0.4019 - val_accuracy: 0.7248 - val_loss: 0.6458\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.8646 - loss: 0.3418 - val_accuracy: 0.7047 - val_loss: 0.6819\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.8875 - loss: 0.3052 - val_accuracy: 0.7114 - val_loss: 0.7561\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 420ms/step - accuracy: 0.8988 - loss: 0.2686 - val_accuracy: 0.7047 - val_loss: 0.8287\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7286 - loss: 0.5419\n",
      "✅ Fold 2 test accuracy: 0.7229\n",
      "\n",
      "🧪 Fold 3 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.6033 - loss: 1.3238 - val_accuracy: 0.5973 - val_loss: 0.6792\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 421ms/step - accuracy: 0.6232 - loss: 0.6817 - val_accuracy: 0.5973 - val_loss: 0.6785\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.6232 - loss: 0.6797 - val_accuracy: 0.5973 - val_loss: 0.6843\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.6232 - loss: 0.6786 - val_accuracy: 0.5973 - val_loss: 0.6764\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 418ms/step - accuracy: 0.6232 - loss: 0.6741 - val_accuracy: 0.5973 - val_loss: 0.6749\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.6232 - loss: 0.6790 - val_accuracy: 0.5973 - val_loss: 0.6856\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6232 - loss: 0.6646 - val_accuracy: 0.5973 - val_loss: 0.6726\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.6244 - loss: 0.6747 - val_accuracy: 0.5973 - val_loss: 0.6684\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6046 - loss: 0.6649 - val_accuracy: 0.5973 - val_loss: 0.6937\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6232 - loss: 0.6768 - val_accuracy: 0.5973 - val_loss: 0.6889\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 420ms/step - accuracy: 0.6232 - loss: 0.6871 - val_accuracy: 0.5973 - val_loss: 0.6851\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6232 - loss: 0.6786 - val_accuracy: 0.5973 - val_loss: 0.6753\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6232 - loss: 0.6726 - val_accuracy: 0.5973 - val_loss: 0.6804\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5978 - loss: 0.6677\n",
      "✅ Fold 3 test accuracy: 0.5783\n",
      "\n",
      "🧪 Fold 4 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.4598 - loss: 0.8606 - val_accuracy: 0.6107 - val_loss: 0.6672\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6011 - loss: 0.6766 - val_accuracy: 0.6107 - val_loss: 0.6670\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.5729 - loss: 0.6771 - val_accuracy: 0.6107 - val_loss: 0.6665\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.5895 - loss: 0.6780 - val_accuracy: 0.6107 - val_loss: 0.6627\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6452 - loss: 0.6489 - val_accuracy: 0.6376 - val_loss: 0.6395\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.7107 - loss: 0.5551 - val_accuracy: 0.7114 - val_loss: 0.6183\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 396ms/step - accuracy: 0.7699 - loss: 0.4798 - val_accuracy: 0.7450 - val_loss: 0.7921\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.8349 - loss: 0.3895 - val_accuracy: 0.7248 - val_loss: 0.6131\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 388ms/step - accuracy: 0.8666 - loss: 0.3120 - val_accuracy: 0.7584 - val_loss: 0.6730\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.8771 - loss: 0.3089 - val_accuracy: 0.7584 - val_loss: 0.6950\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 394ms/step - accuracy: 0.9093 - loss: 0.2625 - val_accuracy: 0.7450 - val_loss: 0.6353\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.9196 - loss: 0.1979 - val_accuracy: 0.7181 - val_loss: 0.7431\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.9531 - loss: 0.1443 - val_accuracy: 0.7248 - val_loss: 0.9947\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8021 - loss: 0.4345\n",
      "✅ Fold 4 test accuracy: 0.8072\n",
      "\n",
      "🧪 Fold 5 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 396ms/step - accuracy: 0.5039 - loss: 0.9029 - val_accuracy: 0.6040 - val_loss: 0.6757\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 402ms/step - accuracy: 0.6342 - loss: 0.6803 - val_accuracy: 0.6040 - val_loss: 0.6834\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6342 - loss: 0.6779 - val_accuracy: 0.6040 - val_loss: 0.6718\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6342 - loss: 0.6665 - val_accuracy: 0.6040 - val_loss: 0.6738\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.6342 - loss: 0.6669 - val_accuracy: 0.6040 - val_loss: 0.6714\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6342 - loss: 0.6634 - val_accuracy: 0.6040 - val_loss: 0.6720\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6342 - loss: 0.6645 - val_accuracy: 0.6040 - val_loss: 0.6705\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 420ms/step - accuracy: 0.6342 - loss: 0.6653 - val_accuracy: 0.6040 - val_loss: 0.6716\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.6342 - loss: 0.6619 - val_accuracy: 0.6040 - val_loss: 0.6662\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6342 - loss: 0.6549 - val_accuracy: 0.6040 - val_loss: 0.6623\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6342 - loss: 0.6548 - val_accuracy: 0.6040 - val_loss: 0.6570\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.5975 - loss: 0.6340 - val_accuracy: 0.6040 - val_loss: 0.6589\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6342 - loss: 0.6239 - val_accuracy: 0.6040 - val_loss: 0.6639\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.6342 - loss: 0.6678 - val_accuracy: 0.6040 - val_loss: 0.6697\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6342 - loss: 0.6064 - val_accuracy: 0.6040 - val_loss: 0.6317\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.6342 - loss: 0.5505 - val_accuracy: 0.6040 - val_loss: 0.6294\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6342 - loss: 0.5410 - val_accuracy: 0.6040 - val_loss: 0.6433\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 397ms/step - accuracy: 0.6350 - loss: 0.4773 - val_accuracy: 0.6510 - val_loss: 0.7052\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.8086 - loss: 0.4318 - val_accuracy: 0.6510 - val_loss: 0.8465\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.8054 - loss: 0.4249 - val_accuracy: 0.6242 - val_loss: 0.6737\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 393ms/step - accuracy: 0.7898 - loss: 0.4627 - val_accuracy: 0.6577 - val_loss: 0.7962\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5740 - loss: 0.6214\n",
      "✅ Fold 5 test accuracy: 0.5542\n",
      "\n",
      "🧪 Fold 6 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - accuracy: 0.5864 - loss: 1.1314 - val_accuracy: 0.5906 - val_loss: 0.6769\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.6331 - loss: 0.6765 - val_accuracy: 0.5906 - val_loss: 0.6822\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6331 - loss: 0.6839 - val_accuracy: 0.5906 - val_loss: 0.6789\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6331 - loss: 0.6716 - val_accuracy: 0.5906 - val_loss: 0.6761\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 393ms/step - accuracy: 0.6331 - loss: 0.6660 - val_accuracy: 0.5906 - val_loss: 0.6761\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.6331 - loss: 0.6644 - val_accuracy: 0.5906 - val_loss: 0.6747\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6331 - loss: 0.6662 - val_accuracy: 0.5906 - val_loss: 0.6915\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6331 - loss: 0.6905 - val_accuracy: 0.5906 - val_loss: 0.6905\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6331 - loss: 0.6890 - val_accuracy: 0.5906 - val_loss: 0.6895\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6331 - loss: 0.6874 - val_accuracy: 0.5906 - val_loss: 0.6885\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6331 - loss: 0.6858 - val_accuracy: 0.5906 - val_loss: 0.6875\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5978 - loss: 0.6693\n",
      "✅ Fold 6 test accuracy: 0.6098\n",
      "\n",
      "🧪 Fold 7 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.5472 - loss: 1.3138 - val_accuracy: 0.5570 - val_loss: 0.6869\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 404ms/step - accuracy: 0.6197 - loss: 0.6767 - val_accuracy: 0.5570 - val_loss: 0.6939\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6197 - loss: 0.6718 - val_accuracy: 0.5570 - val_loss: 0.6854\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6169 - loss: 0.6796 - val_accuracy: 0.5570 - val_loss: 0.6854\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 400ms/step - accuracy: 0.6197 - loss: 0.6644 - val_accuracy: 0.5570 - val_loss: 0.6735\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6180 - loss: 0.6336 - val_accuracy: 0.6443 - val_loss: 0.6490\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 395ms/step - accuracy: 0.6569 - loss: 0.6123 - val_accuracy: 0.6577 - val_loss: 0.6507\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.7460 - loss: 0.5497 - val_accuracy: 0.6309 - val_loss: 0.6439\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.7217 - loss: 0.5412 - val_accuracy: 0.6443 - val_loss: 0.6697\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 406ms/step - accuracy: 0.7710 - loss: 0.4822 - val_accuracy: 0.6644 - val_loss: 0.6939\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.8011 - loss: 0.4571 - val_accuracy: 0.6510 - val_loss: 0.7339\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.8580 - loss: 0.3412 - val_accuracy: 0.6577 - val_loss: 0.7759\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.8912 - loss: 0.2962 - val_accuracy: 0.6644 - val_loss: 0.7903\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7726 - loss: 0.5509\n",
      "✅ Fold 7 test accuracy: 0.7561\n",
      "\n",
      "🧪 Fold 8 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - accuracy: 0.4881 - loss: 0.8596 - val_accuracy: 0.5705 - val_loss: 0.6826\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6403 - loss: 0.6765 - val_accuracy: 0.5705 - val_loss: 0.6930\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6403 - loss: 0.6721 - val_accuracy: 0.5705 - val_loss: 0.6847\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.6403 - loss: 0.6741 - val_accuracy: 0.5705 - val_loss: 0.6922\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.6299 - loss: 0.6712 - val_accuracy: 0.5705 - val_loss: 0.6810\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.6403 - loss: 0.6696 - val_accuracy: 0.5705 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6403 - loss: 0.6741 - val_accuracy: 0.5705 - val_loss: 0.6869\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 405ms/step - accuracy: 0.6403 - loss: 0.6706 - val_accuracy: 0.5705 - val_loss: 0.6959\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6403 - loss: 0.6684 - val_accuracy: 0.5705 - val_loss: 0.6843\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.6403 - loss: 0.6656 - val_accuracy: 0.5705 - val_loss: 0.6832\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5161 - loss: 0.7088\n",
      "✅ Fold 8 test accuracy: 0.5244\n",
      "\n",
      "🧪 Fold 9 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 418ms/step - accuracy: 0.5726 - loss: 0.8431 - val_accuracy: 0.5570 - val_loss: 0.6879\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6332 - loss: 0.6715 - val_accuracy: 0.5570 - val_loss: 0.6864\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6332 - loss: 0.6646 - val_accuracy: 0.5570 - val_loss: 0.6790\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6332 - loss: 0.6534 - val_accuracy: 0.5570 - val_loss: 0.6643\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.6350 - loss: 0.6193 - val_accuracy: 0.6779 - val_loss: 0.6575\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - accuracy: 0.6786 - loss: 0.5921 - val_accuracy: 0.6913 - val_loss: 0.6625\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 389ms/step - accuracy: 0.7501 - loss: 0.5317 - val_accuracy: 0.6644 - val_loss: 0.6552\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 368ms/step - accuracy: 0.7656 - loss: 0.4963 - val_accuracy: 0.6711 - val_loss: 0.6518\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.7965 - loss: 0.4481 - val_accuracy: 0.6980 - val_loss: 0.6617\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 351ms/step - accuracy: 0.8278 - loss: 0.4055 - val_accuracy: 0.6846 - val_loss: 0.7355\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.8426 - loss: 0.3589 - val_accuracy: 0.6913 - val_loss: 0.8459\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 351ms/step - accuracy: 0.8834 - loss: 0.3016 - val_accuracy: 0.6644 - val_loss: 0.8617\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 343ms/step - accuracy: 0.9222 - loss: 0.2181 - val_accuracy: 0.5973 - val_loss: 0.8652\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6996 - loss: 0.6209\n",
      "✅ Fold 9 test accuracy: 0.7195\n",
      "\n",
      "🧪 Fold 10 -----------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 349ms/step - accuracy: 0.5234 - loss: 0.8374 - val_accuracy: 0.5839 - val_loss: 0.6791\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step - accuracy: 0.6173 - loss: 0.6741 - val_accuracy: 0.5839 - val_loss: 0.6825\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.6173 - loss: 0.6743 - val_accuracy: 0.5839 - val_loss: 0.6774\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 493ms/step - accuracy: 0.6173 - loss: 0.6654 - val_accuracy: 0.5839 - val_loss: 0.6752\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.6173 - loss: 0.6619 - val_accuracy: 0.5839 - val_loss: 0.6718\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.6173 - loss: 0.6500 - val_accuracy: 0.5839 - val_loss: 0.6565\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 410ms/step - accuracy: 0.6173 - loss: 0.6278 - val_accuracy: 0.5839 - val_loss: 0.6492\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 409ms/step - accuracy: 0.6189 - loss: 0.5627 - val_accuracy: 0.6913 - val_loss: 0.6565\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.7534 - loss: 0.5542 - val_accuracy: 0.6913 - val_loss: 0.6678\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.7316 - loss: 0.5240 - val_accuracy: 0.6846 - val_loss: 0.7129\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.7796 - loss: 0.4907 - val_accuracy: 0.7047 - val_loss: 0.6795\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 414ms/step - accuracy: 0.8008 - loss: 0.4512 - val_accuracy: 0.6980 - val_loss: 0.7496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6952 - loss: 0.5346\n",
      "✅ Fold 10 test accuracy: 0.6951\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 3: K-Fold Cross-Validation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# define it once (you can tweak patience, monitor, etc. as you like)\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',        # watch validation loss\n",
    "    patience=5,               # stop if no improvement for 10 epochs\n",
    "    restore_best_weights=True  # roll back to the best weights seen\n",
    ")\n",
    "\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "all_test_accuracies = []\n",
    "\n",
    "for trainval_index, test_index in kf.split(filepaths):\n",
    "    print(f\"\\n🧪 Fold {fold} -----------------------------\")\n",
    "\n",
    "    # Split into trainval and test\n",
    "    X_trainval, X_test = filepaths[trainval_index], filepaths[test_index]\n",
    "    y_trainval, y_test = labels[trainval_index], labels[test_index]\n",
    "\n",
    "    # Further split trainval into train and val (e.g. 80/20)\n",
    "    val_split = int(0.8 * len(X_trainval))\n",
    "    X_train, X_val = X_trainval[:val_split], X_trainval[val_split:]\n",
    "    y_train, y_val = y_trainval[:val_split], y_trainval[val_split:]\n",
    "\n",
    "\n",
    "    def preprocess(paths, labels):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "        def load_img(path, label):\n",
    "            img = tf.io.read_file(path)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, [224, 224])\n",
    "            img = img / 255.0\n",
    "            return img, label\n",
    "\n",
    "        return ds.map(load_img).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = preprocess(X_train, y_train)\n",
    "    val_ds = preprocess(X_val, y_val)\n",
    "    test_ds = preprocess(X_test, y_test)\n",
    "\n",
    "\n",
    "    # Build a fresh model for each fold\n",
    "    def create_model():\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=(224, 224, 3)),\n",
    "            layers.Conv2D(32, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "    # # Train\n",
    "    # model.fit(train_ds, validation_data=val_ds, epochs=100, verbose=1)\n",
    "\n",
    "    # Train with early stopping\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,            # generous upper bound\n",
    "        callbacks=[earlystop], # ← here!\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    all_test_accuracies.append(test_acc)\n",
    "    print(f\"✅ Fold {fold} test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266fba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 10-Fold Test Accuracy: 0.6630 ± 0.0885\n"
     ]
    }
   ],
   "source": [
    "# Cell Block 4: Final Evaluation\n",
    "mean_acc = np.mean(all_test_accuracies)\n",
    "std_acc = np.std(all_test_accuracies)\n",
    "print(f\"\\n📊 {k}-Fold Test Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
